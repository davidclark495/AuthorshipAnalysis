{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTS**"
      ],
      "metadata": {
        "id": "oQa8Oy-nS_9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')  \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import bigrams\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import re\n",
        "import math\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD7zS478S9C_",
        "outputId": "e98100f9-debb-4c6d-9f5a-af0526537818"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOADING CORPUS**"
      ],
      "metadata": {
        "id": "uH0cKXAoUH7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/AuthorshipAnalysisFiles\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7P6hREE89uc",
        "outputId": "36bcf3da-ab97-4b7c-9945-339dbb7e6aa1"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allen-p   bass-e     buy-r\t delainey-d\t\t     fossum-d\n",
            "arnold-j  beck-s     campbell-l  enron_mail_20150507.tar.gz\n",
            "badeer-r  brawner-s  carson-m\t farmer-d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# files are organized under\n",
        "#   /project_dir\n",
        "#     /name           \n",
        "#       /_sent_mail   \n",
        "#         /1.          \n",
        "\n",
        "# define common path substr's\n",
        "project_dir = \"/content/drive/MyDrive/AuthorshipAnalysisFiles\"\n",
        "sent_suffix = \"_sent_mail\""
      ],
      "metadata": {
        "id": "1JSD4c9v9sXx"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define distinct authors' directories\n",
        "project_folder_ls_text = !ls -F $project_dir\n",
        "project_folder_items = project_folder_ls_text.nlstr.split()\n",
        "\n",
        "project_authors = [item.strip('/') for item in project_folder_items if item.endswith('/')]\n",
        "\n",
        "NUM_AUTHORS = 9999 # truncate # of authors (& amount of data/processing) here, if desired\n",
        "project_authors = project_authors[0:NUM_AUTHORS]\n",
        "\n",
        "authors_paths =       { author: f\"{project_dir}/{author}\" for author in project_authors}\n",
        "authors_sent_paths =  { author: f\"{project_dir}/{author}/{sent_suffix}\" for author in project_authors}\n",
        "\n",
        "# DEBUG OUTPUT\n",
        "print(project_folder_items)\n",
        "for folder in project_authors:\n",
        "  print(folder)\n",
        "for path in authors_paths.values():\n",
        "  print(path)\n",
        "for path in authors_sent_paths.values():\n",
        "  print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YH2fW6kdHwD",
        "outputId": "e33f963d-cf24-4d0d-a393-4be624087f3c"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['allen-p/', 'bass-e/', 'buy-r/', 'delainey-d/', 'fossum-d/', 'arnold-j/', 'beck-s/', 'campbell-l/', 'enron_mail_20150507.tar.gz', 'badeer-r/', 'brawner-s/', 'carson-m/', 'farmer-d/']\n",
            "allen-p\n",
            "bass-e\n",
            "buy-r\n",
            "delainey-d\n",
            "fossum-d\n",
            "arnold-j\n",
            "beck-s\n",
            "campbell-l\n",
            "badeer-r\n",
            "brawner-s\n",
            "carson-m\n",
            "farmer-d\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/allen-p\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/bass-e\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/buy-r\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/delainey-d\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/fossum-d\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/arnold-j\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/beck-s\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/campbell-l\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/badeer-r\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/brawner-s\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/carson-m\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/farmer-d\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/allen-p/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/bass-e/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/buy-r/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/delainey-d/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/fossum-d/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/arnold-j/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/beck-s/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/campbell-l/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/badeer-r/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/brawner-s/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/carson-m/_sent_mail\n",
            "/content/drive/MyDrive/AuthorshipAnalysisFiles/farmer-d/_sent_mail\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define list of authors' email paths\n",
        "authors_sent_email_paths = {}\n",
        "\n",
        "for author in project_authors:\n",
        "  path = authors_sent_paths[author]\n",
        "  sent_dir_ls = !ls $path \n",
        "  sent_dir_items = sent_dir_ls.nlstr.split()\n",
        "  path_list = []\n",
        "  for item in sent_dir_items:\n",
        "    path_list.append(f\"{path}/{item}\")\n",
        "  authors_sent_email_paths[author] = path_list\n",
        "\n",
        "# DEBUG OUTPUT\n",
        "print(\"SAMPLE\")\n",
        "for author in project_authors[0:2]:\n",
        "  print(author)\n",
        "  path_list = authors_sent_email_paths[author]\n",
        "  for path in path_list[0:2]:\n",
        "    print(f\"\\t{path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HlUZOFCy3NB",
        "outputId": "5b864461-72b6-4905-aead-ba6565e4698c"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE\n",
            "allen-p\n",
            "\t/content/drive/MyDrive/AuthorshipAnalysisFiles/allen-p/_sent_mail/1.\n",
            "\t/content/drive/MyDrive/AuthorshipAnalysisFiles/allen-p/_sent_mail/137.\n",
            "bass-e\n",
            "\t/content/drive/MyDrive/AuthorshipAnalysisFiles/bass-e/_sent_mail/1.\n",
            "\t/content/drive/MyDrive/AuthorshipAnalysisFiles/bass-e/_sent_mail/1104.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# running this cell w/ 3 authors takes ~= 3 minutes\n",
        "\n",
        "# define list of author's emails\n",
        "authors_emails = {}\n",
        "for author in project_authors:\n",
        "  path_list = authors_sent_email_paths[author]\n",
        "  email_list = []\n",
        "  for path in path_list:\n",
        "    with open(path, \"r\") as f:\n",
        "      email_list.append(f.read())\n",
        "      f.close()\n",
        "  authors_emails[author] = email_list\n",
        "\n",
        "# DEBUG OUTPUT\n",
        "print(\"SAMPLE\")\n",
        "for author in project_authors[0:3]:\n",
        "  print(author)\n",
        "  email_list = authors_emails[author]\n",
        "  for email in email_list[0:2]:\n",
        "    print(f\"EMAIL START\\n{email}\\nEMAIL END\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "K2VSSZ_0wWxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bbef3d-d1d4-4366-c816-af36b31ac97f"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE\n",
            "allen-p\n",
            "EMAIL START\n",
            "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
            "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
            "From: phillip.allen@enron.com\n",
            "To: tim.belden@enron.com\n",
            "Subject: \n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Phillip K Allen\n",
            "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
            "X-Origin: Allen-P\n",
            "X-FileName: pallen (Non-Privileged).pst\n",
            "\n",
            "Here is our forecast\n",
            "\n",
            " \n",
            "EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "Message-ID: <23377438.1075855688269.JavaMail.evans@thyme>\n",
            "Date: Tue, 12 Sep 2000 06:06:00 -0700 (PDT)\n",
            "From: phillip.allen@enron.com\n",
            "To: stagecoachmama@hotmail.com\n",
            "Subject: \n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Phillip K Allen\n",
            "X-To: stagecoachmama@hotmail.com\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail\n",
            "X-Origin: Allen-P\n",
            "X-FileName: pallen.nsf\n",
            "\n",
            "Lucy,\n",
            "\n",
            "\n",
            "You wrote fewer checks this month.  Spent more money on Materials and less on \n",
            "Labor.\n",
            "\n",
            "\n",
            "   June  July  August\n",
            "\n",
            "Total Materials  2929  4085  4801\n",
            "\n",
            "Services  53  581  464\n",
            "\n",
            "Labor   3187  3428  2770\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Here are my questions on the August bank statement (attached):\n",
            "\n",
            "1.  Check 1406  Walmart    Description and unit?\n",
            "\n",
            "2.  Check 1410  Crumps     Detail description and unit?\n",
            "\n",
            "3.  Check 1411  Lucy      What is this?\n",
            "\n",
            "4.  Check 1415  Papes      Detail description and units?\n",
            "\n",
            "5.  Checks 1416, 1417, and 1425  Why overtime?\n",
            "\n",
            "6.  Check 1428    Ralph's   What unit?\n",
            "\n",
            "7.  Check 1438    Walmart?    Description and unit?  \n",
            "\n",
            "\n",
            "Try and pull together the support for these items and get back to me.\n",
            "\n",
            "Phillip\n",
            "EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "bass-e\n",
            "EMAIL START\n",
            "Message-ID: <17027752.1075840325838.JavaMail.evans@thyme>\n",
            "Date: Fri, 9 Mar 2001 11:24:00 -0800 (PST)\n",
            "From: eric.bass@enron.com\n",
            "To: chance.rabon@enron.com\n",
            "Subject: Rebook - QU0663 Mirant\n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Eric Bass\n",
            "X-To: Chance Rabon <Chance Rabon/ENRON@enronXgate>\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\ExMerge - Bass, Eric\\'Sent Mail\n",
            "X-Origin: BASS-E\n",
            "X-FileName: eric bass 6-25-02.PST\n",
            "\n",
            "\n",
            "---------------------- Forwarded by Eric Bass/HOU/ECT on 03/09/2001 08:24 AM ---------------------------\n",
            "   \n",
            "\t  From:  Larry Joe Hunter                           03/08/2001 05:53 PM\t\n",
            "\t\t\n",
            "\n",
            "\n",
            "To:\tEric Bass/HOU/ECT@ECT\n",
            "cc:\tJanie Aguayo/HOU/ECT@ECT \n",
            "Subject:\tRebook - QU0663 Mirant\n",
            "\n",
            "Eric,\n",
            "\n",
            "Can you adjust TAGG shortname to MIRANTAMEENE  (currently MIRANTAMEENECAN)?\n",
            "\n",
            "Thanks,\n",
            "Joe\n",
            "\n",
            "\n",
            "\n",
            "EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "Message-ID: <18098864.1075854732776.JavaMail.evans@thyme>\n",
            "Date: Thu, 6 Jan 2000 02:30:00 -0800 (PST)\n",
            "From: eric.bass@enron.com\n",
            "To: michael.walters@enron.com, david.baumbach@enron.com, \n",
            "\to'neal.winfree@enron.com, bryan.hull@enron.com\n",
            "Subject: follow thi link\n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Eric Bass\n",
            "X-To: Michael Walters, David Baumbach, O'Neal D Winfree, Bryan Hull\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\Eric_Bass_Dec2000\\Notes Folders\\'sent mail\n",
            "X-Origin: Bass-E\n",
            "X-FileName: ebass.nsf\n",
            "\n",
            "---------------------- Forwarded by Eric Bass/HOU/ECT on 01/06/2000 10:29 AM \n",
            "---------------------------\n",
            "To: Eric Bass/HOU/ECT@ECT\n",
            "cc:  \n",
            "Subject: follow thi link\n",
            "\n",
            "http://www.altavista.com/cgi-bin/query?pg=q&sc=on&q=register+domain&kl=XX&styp\n",
            "e=stext\n",
            "\n",
            "EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "buy-r\n",
            "EMAIL START\n",
            "Message-ID: <15796365.1075858306293.JavaMail.evans@thyme>\n",
            "Date: Wed, 13 Dec 2000 06:27:00 -0800 (PST)\n",
            "From: karen.heathman@enron.com\n",
            "To: william.bradford@enron.com, rick.carson@enron.com, david.gorte@enron.com, \n",
            "\tted.murphy@enron.com, mark.ruane@enron.com, steve.young@enron.com\n",
            "Subject: RAC Holiday Coverage\n",
            "Cc: dorothy.youngblood@enron.com, bobbie.campbell@enron.com, \n",
            "\tpam.metoyer@enron.com, rita.hennessy@enron.com, \n",
            "\tdenise.naiser@enron.com, claire.dunnett@enron.com, \n",
            "\tveronica.valdez@enron.com\n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "Bcc: dorothy.youngblood@enron.com, bobbie.campbell@enron.com, \n",
            "\tpam.metoyer@enron.com, rita.hennessy@enron.com, \n",
            "\tdenise.naiser@enron.com, claire.dunnett@enron.com, \n",
            "\tveronica.valdez@enron.com\n",
            "X-From: Karen K Heathman\n",
            "X-To: William S Bradford, Rick L Carson, David Gorte, Ted Murphy, Mark Ruane, Steve W Young\n",
            "X-cc: Dorothy Youngblood, Bobbie Campbell, Pam Metoyer, Rita Hennessy, Denise Naiser, Claire Dunnett, Veronica Valdez\n",
            "X-bcc: \n",
            "X-Folder: \\Richard_Buy_Dec2000\\Notes Folders\\'sent mail\n",
            "X-Origin: Buy-R\n",
            "X-FileName: rbuy.nsf\n",
            "\n",
            "I will be out of the office the week between Christmas and New Year's and can \n",
            "be contacted by telephone and fax @ (603) 875-0794.\n",
            "Please make certain that there is coverage at all times for your area.   \n",
            "Also, please send Karen your own schedule.\n",
            "\n",
            "Rick\n",
            "EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "Message-ID: <7520618.1075858306506.JavaMail.evans@thyme>\n",
            "Date: Mon, 4 Dec 2000 23:55:00 -0800 (PST)\n",
            "From: rick.buy@enron.com\n",
            "To: ted.murphy@enron.com\n",
            "Subject: VAR\n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Rick Buy\n",
            "X-To: Ted Murphy\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\Richard_Buy_Dec2000\\Notes Folders\\'sent mail\n",
            "X-Origin: Buy-R\n",
            "X-FileName: rbuy.nsf\n",
            "\n",
            "fyi, rick\n",
            "---------------------- Forwarded by Rick Buy/HOU/ECT on 12/05/2000 07:54 AM \n",
            "---------------------------\n",
            "\n",
            "\n",
            "John L Nowlan\n",
            "12/04/2000 05:53 PM\n",
            "To: Rick Buy/HOU/ECT@ECT, Jeffrey A Shankman/HOU/ECT@ECT, Mike \n",
            "McConnell/HOU/ECT@ECT\n",
            "cc:  \n",
            "Subject: VAR\n",
            "\n",
            "Recognizing we were just below daily VAR limits today, coupled with the high \n",
            "volatility in the crude and products markets, we attempted to do an interday \n",
            "calc. Unfortunately it took us some time to get the right person but we did \n",
            "succeed in getting an  estimate right at the close which showed we were very \n",
            "near our limits as we were yesterday. I flag this up to point out it is \n",
            "critical in these ,markets that we have some cover or know who we can call if \n",
            "we need this type of interday analysis. \n",
            "\n",
            "EMAIL END\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROCESSING EMAILS**"
      ],
      "metadata": {
        "id": "7rJDxHdenRqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define list of authors' emails: w/o headers\n",
        "\n",
        "# forgive me for my RegEx sins\n",
        "\n",
        "# get a list of emails w/o headers\n",
        "def get_email_bodies(emails: list):\n",
        "  # assume header lines are of the form\n",
        "  #   Header-Name: some <string> of AR8itrary Symbols \\n  \n",
        "  first_divider_line_regex = r\"^\\-{5,} .*(?=\\n)\"\n",
        "  divider_line_regex = r\"(?<=\\n)\\-{5,} .*(?=\\n)\"\n",
        "  first_header_line_regex = r\"^[a-zA-Z\\-]*:\\s.*(?=\\n)\"\n",
        "  header_line_regex = r\"(?<=\\n)[a-zA-Z\\-]*:\\s.*(?=\\n)\"\n",
        "  empty_line_regex = r\"\\n(?=\\n)\"\n",
        "  name_line_regex = r\"(?<=\\n)[\\w@]*(\\s[\\w@]*)?,?(?=\\n)\"       # <-- catches one or two words (hopefully names) w/ optional ','\n",
        "  name_end_regex = r\"(?<=\\n)[\\w@]*(\\s[\\w@]*)?$\"               # <-- catches one or two words (hopefully names) at end of string\n",
        "  date_regex = r\"(?<=\\s)(\\d{1,2})/(\\d{1,2})/(\\d{2,4})(?=\\s)\"  # e.g. XX/YY/ZZ or X/Y/ZZZZ or variations (first. approximation)\n",
        "  time_regex = r\"(?<=(\\s|\\-))(\\d{1,2}):(\\d{2})(:\\d{2})?( AM| PM)?(?=(\\s|\\-))\"  # e.g. 01:02 AM or 01:02:03 PM or variations (first. approximation)\n",
        "\n",
        "  email_bodies = []\n",
        "  for email in emails:\n",
        "    email_body = email\n",
        "    # remove header lines\n",
        "    email_body = re.sub(divider_line_regex,      \"\", email_body)\n",
        "    email_body = re.sub(first_divider_line_regex,\"\", email_body)\n",
        "    email_body = re.sub(header_line_regex,       \"\", email_body)\n",
        "    email_body = re.sub(first_header_line_regex, \"\", email_body)\n",
        "    # remove signature / address line (not precise, first-order-approximation)\n",
        "    email_body = re.sub(name_line_regex,         \"\", email_body)\n",
        "    email_body = re.sub(name_end_regex,          \"\", email_body)\n",
        "    # remove dates / times\n",
        "    email_body = re.sub(date_regex,              \"DATE\", email_body)\n",
        "    email_body = re.sub(time_regex,              \"TIME\", email_body)\n",
        "    # remove blank lines\n",
        "    email_body = re.sub(empty_line_regex,        \"\", email_body)\n",
        "    email_body = email_body.strip()\n",
        "    email_bodies.append(email_body)\n",
        "  return email_bodies\n",
        "\n",
        "authors_email_bodies = {}\n",
        "for author in project_authors:\n",
        "  email_list = authors_emails[author]\n",
        "  authors_email_bodies[author] = get_email_bodies(email_list)\n",
        "\n",
        "# DEBUG OUTPUT\n",
        "print(\"SAMPLE\")\n",
        "for author in project_authors[0:3]:\n",
        "  print(author)\n",
        "  email_list = authors_email_bodies[author]\n",
        "  for email in email_list[0:5]:\n",
        "    print(f\"EMAIL START\\n{email}EMAIL END\\n\\n\\n\")\n",
        "  print(\"*************\")\n"
      ],
      "metadata": {
        "id": "Vwm8MWzT5yGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5c3d40-4659-4c9e-9d09-cf9aab172bb0"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE\n",
            "allen-p\n",
            "EMAIL START\n",
            "Here is our forecastEMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "You wrote fewer checks this month.  Spent more money on Materials and less on \n",
            "Labor.\n",
            "   June  July  August\n",
            "Total Materials  2929  4085  4801\n",
            "Services  53  581  464\n",
            "Labor   3187  3428  2770\n",
            "Here are my questions on the August bank statement (attached):\n",
            "1.  Check 1406  Walmart    Description and unit?\n",
            "2.  Check 1410  Crumps     Detail description and unit?\n",
            "3.  Check 1411  Lucy      What is this?\n",
            "4.  Check 1415  Papes      Detail description and units?\n",
            "5.  Checks 1416, 1417, and 1425  Why overtime?\n",
            "6.  Check 1428    Ralph's   What unit?\n",
            "7.  Check 1438    Walmart?    Description and unit?  \n",
            "Try and pull together the support for these items and get back to me.EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "DATE TIME\n",
            "I got this request.  On the gas side, I think Kean/Lay need an update to a table you prepared for me a few months ago, which I've attached..  Can you oblige?  Thanks,\n",
            "DATE TIME\n",
            "Steve has asked that you update the power point below so that it reflects all of the \"stupid regulatory/legislative decisions\" since the beginning of the year.  Ken wants to have this updated chart in his briefing book for next week's \"Ken Lay Tour\" to CA.  \n",
            "He also wants a forward price curve for both gas and power in CA.  Can we get these three documents by Monday afternoon?EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "How about Tuesday at TIME in front of the building?EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "No one will be home on DATE to meet DSL installers.  Need to reschedule to \n",
            "the following week.  Also, my PC at home has Windows 95.  Is this a problem? \n",
            "Call with questions. X37041.EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "*************\n",
            "bass-e\n",
            "EMAIL START\n",
            "From:  Larry Joe Hunter                           DATE TIME\t\n",
            "\t\t\n",
            "Can you adjust TAGG shortname to MIRANTAMEENE  (currently MIRANTAMEENECAN)?EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "o'neal.winfree@enron.com, bryan.hull@enron.com\n",
            "---------------------------\n",
            "http://www.altavista.com/cgi-bin/query?pg=q&sc=on&q=register+domain&kl=XX&styp\n",
            "e=stextEMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "I still need to get this approval.\n",
            "---------------------------\n",
            "Eric Bass   DATE TIME\n",
            "I need to get IF GD/D Waha for Mar approved.\n",
            "Thanks in advance,EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "---------------------------\n",
            "Susan M Scott\n",
            "DATE TIME\n",
            "McLaughlin/Corp/Enron@ENRON, celeahy@hotmail.com, d.epperson@mail.utexas.edu, \n",
            "Eric Bass/HOU/ECT@ECT, ehillegeist@hotmail.com, jkbowles@hotmail.com, \n",
            "emily.boon@msdw.com \n",
            "PM ---------------------------\n",
            "   \n",
            "\tEnron Capital & Trade Resources Corp.\n",
            "\tFrom:  Mason Hamlin                           DATE TIME\n",
            "House/HOU/ECT@ECT, Lisa Gillette/HOU/ECT@ECT, Susan M Scott/HOU/ECT@ECT, John \n",
            "Swinney/HOU/ECT@ECT, Scott Earnest/HOU/ECT@ECT, Michelle Bruce/HOU/ECT@ECT, \n",
            "Zachary McCarroll/Enron Communications@Enron Communications\n",
            " - Priceless.jpgEMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "Shanna and I were wondering what you and Donnita were doing for New Years?\n",
            "-EricEMAIL END\n",
            "\n",
            "\n",
            "\n",
            "*************\n",
            "buy-r\n",
            "EMAIL START\n",
            "ted.murphy@enron.com, mark.ruane@enron.com, steve.young@enron.com\n",
            "\tpam.metoyer@enron.com, rita.hennessy@enron.com, \n",
            "\tdenise.naiser@enron.com, claire.dunnett@enron.com, \n",
            "\tveronica.valdez@enron.com\n",
            "\tpam.metoyer@enron.com, rita.hennessy@enron.com, \n",
            "\tdenise.naiser@enron.com, claire.dunnett@enron.com, \n",
            "\tveronica.valdez@enron.com\n",
            "I will be out of the office the week between Christmas and New Year's and can \n",
            "be contacted by telephone and fax @ (603) 875-0794.\n",
            "Please make certain that there is coverage at all times for your area.   \n",
            "Also, please send Karen your own schedule.EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "fyi, rick\n",
            "---------------------------\n",
            "John L Nowlan\n",
            "DATE TIME\n",
            "McConnell/HOU/ECT@ECT\n",
            "Recognizing we were just below daily VAR limits today, coupled with the high \n",
            "volatility in the crude and products markets, we attempted to do an interday \n",
            "calc. Unfortunately it took us some time to get the right person but we did \n",
            "succeed in getting an  estimate right at the close which showed we were very \n",
            "near our limits as we were yesterday. I flag this up to point out it is \n",
            "critical in these ,markets that we have some cover or know who we can call if \n",
            "we need this type of interday analysis.EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "fyi- wasn't there a discussion on this at prc? rick\n",
            "---------------------------\n",
            "   \n",
            "\tFrom:  William S Bradford                           DATE TIME\n",
            "Rohauer/HOU/ECT@ECT, Rod Nelson/LON/ECT@ECT \n",
            "We actually forced Craig Breslau and Fred Lagrasta to unwind an unapproved \n",
            "one year trade with their subsidiary Savannah Foods in April 2000.  In \n",
            "hindsight, it appears to be quite a good call.\n",
            "TIME ---------------------------\n",
            "Jason R Williams@ENRON\n",
            "DATE TIME\n",
            "Moran/HOU/ECT@ECT, Russell Diamond/HOU/ECT@ECT, Brant Reves/HOU/ECT@ECT, \n",
            "Veronica Espinoza/Corp/Enron@ENRON, Rudwell Johnson/NA/Enron@ENRON, Darren \n",
            "Vanek/NA/Enron@Enron\n",
            "FYI, Imperial Holly Corporation filed for Chapter 11 protection yesterday.  \n",
            "Counterparties affected would be:\n",
            "  Imperial Holly Corporation\n",
            "  Holly Sugar Corporation\n",
            "At the present, we have no trades with either of these counterparties.EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "Attorney client privilege\n",
            "I guess I don't have strong feelings if a dash is written here or not but I \n",
            "do care that a troubled situation receive the attention it requires to avoid \n",
            "getting in deeper. There always seems to be reluctance in UK to have a dash \n",
            "prepared, Steve always used a huge amount of energy on justifying the task. \n",
            "We all know that if problem deals are not addressed they always get worse. \n",
            "Maybe Michael could be led to \"suggest\" an alternative memo or approach. A \n",
            "\"problem deal\" memo. If you all think a dash is the best approach do it and I \n",
            "don't care if they don't sign it.\n",
            "Once the website is functional, it will be helpful to have a complete history \n",
            "of deals and having these kind of memos in dash format will aid this process. \n",
            "One final thought, Michael is quite supportive of our effort and I think we \n",
            "should pick battles carefully. RickEMAIL END\n",
            "\n",
            "\n",
            "\n",
            "EMAIL START\n",
            "connie.f.estrems@enron.com\n",
            "I have done this 3 times now.EMAIL END\n",
            "\n",
            "\n",
            "\n",
            "*************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define list of authors' emails, tokenized\n",
        "authors_tokenized_emails = {}\n",
        "for author in project_authors:\n",
        "  tokenized_emails = []\n",
        "  for email in authors_email_bodies[author]:\n",
        "    tokenized = nltk.word_tokenize(email)\n",
        "    tokenized_emails.append(tokenized)\n",
        "  authors_tokenized_emails[author] = tokenized_emails\n",
        "\n",
        "# DEBUG OUTPUT\n",
        "print(\"SAMPLE\")\n",
        "for author in project_authors:\n",
        "  print(author)\n",
        "  email_list = authors_tokenized_emails[author]\n",
        "  for email_tokens in email_list[0:2]:\n",
        "    print(f\"\\t{email_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVXI8b8Y774E",
        "outputId": "c5be8f19-f8d5-4ec8-fe7d-086aa0a8322a"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE\n",
            "allen-p\n",
            "\t['Here', 'is', 'our', 'forecast']\n",
            "\t['You', 'wrote', 'fewer', 'checks', 'this', 'month', '.', 'Spent', 'more', 'money', 'on', 'Materials', 'and', 'less', 'on', 'Labor', '.', 'June', 'July', 'August', 'Total', 'Materials', '2929', '4085', '4801', 'Services', '53', '581', '464', 'Labor', '3187', '3428', '2770', 'Here', 'are', 'my', 'questions', 'on', 'the', 'August', 'bank', 'statement', '(', 'attached', ')', ':', '1', '.', 'Check', '1406', 'Walmart', 'Description', 'and', 'unit', '?', '2', '.', 'Check', '1410', 'Crumps', 'Detail', 'description', 'and', 'unit', '?', '3', '.', 'Check', '1411', 'Lucy', 'What', 'is', 'this', '?', '4', '.', 'Check', '1415', 'Papes', 'Detail', 'description', 'and', 'units', '?', '5', '.', 'Checks', '1416', ',', '1417', ',', 'and', '1425', 'Why', 'overtime', '?', '6', '.', 'Check', '1428', 'Ralph', \"'s\", 'What', 'unit', '?', '7', '.', 'Check', '1438', 'Walmart', '?', 'Description', 'and', 'unit', '?', 'Try', 'and', 'pull', 'together', 'the', 'support', 'for', 'these', 'items', 'and', 'get', 'back', 'to', 'me', '.']\n",
            "bass-e\n",
            "\t['From', ':', 'Larry', 'Joe', 'Hunter', 'DATE', 'TIME', 'Can', 'you', 'adjust', 'TAGG', 'shortname', 'to', 'MIRANTAMEENE', '(', 'currently', 'MIRANTAMEENECAN', ')', '?']\n",
            "\t[\"o'neal.winfree\", '@', 'enron.com', ',', 'bryan.hull', '@', 'enron.com', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', 'http', ':', '//www.altavista.com/cgi-bin/query', '?', 'pg=q', '&', 'sc=on', '&', 'q=register+domain', '&', 'kl=XX', '&', 'styp', 'e=stext']\n",
            "buy-r\n",
            "\t['ted.murphy', '@', 'enron.com', ',', 'mark.ruane', '@', 'enron.com', ',', 'steve.young', '@', 'enron.com', 'pam.metoyer', '@', 'enron.com', ',', 'rita.hennessy', '@', 'enron.com', ',', 'denise.naiser', '@', 'enron.com', ',', 'claire.dunnett', '@', 'enron.com', ',', 'veronica.valdez', '@', 'enron.com', 'pam.metoyer', '@', 'enron.com', ',', 'rita.hennessy', '@', 'enron.com', ',', 'denise.naiser', '@', 'enron.com', ',', 'claire.dunnett', '@', 'enron.com', ',', 'veronica.valdez', '@', 'enron.com', 'I', 'will', 'be', 'out', 'of', 'the', 'office', 'the', 'week', 'between', 'Christmas', 'and', 'New', 'Year', \"'s\", 'and', 'can', 'be', 'contacted', 'by', 'telephone', 'and', 'fax', '@', '(', '603', ')', '875-0794', '.', 'Please', 'make', 'certain', 'that', 'there', 'is', 'coverage', 'at', 'all', 'times', 'for', 'your', 'area', '.', 'Also', ',', 'please', 'send', 'Karen', 'your', 'own', 'schedule', '.']\n",
            "\t['fyi', ',', 'rick', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', 'John', 'L', 'Nowlan', 'DATE', 'TIME', 'McConnell/HOU/ECT', '@', 'ECT', 'Recognizing', 'we', 'were', 'just', 'below', 'daily', 'VAR', 'limits', 'today', ',', 'coupled', 'with', 'the', 'high', 'volatility', 'in', 'the', 'crude', 'and', 'products', 'markets', ',', 'we', 'attempted', 'to', 'do', 'an', 'interday', 'calc', '.', 'Unfortunately', 'it', 'took', 'us', 'some', 'time', 'to', 'get', 'the', 'right', 'person', 'but', 'we', 'did', 'succeed', 'in', 'getting', 'an', 'estimate', 'right', 'at', 'the', 'close', 'which', 'showed', 'we', 'were', 'very', 'near', 'our', 'limits', 'as', 'we', 'were', 'yesterday', '.', 'I', 'flag', 'this', 'up', 'to', 'point', 'out', 'it', 'is', 'critical', 'in', 'these', ',', 'markets', 'that', 'we', 'have', 'some', 'cover', 'or', 'know', 'who', 'we', 'can', 'call', 'if', 'we', 'need', 'this', 'type', 'of', 'interday', 'analysis', '.']\n",
            "delainey-d\n",
            "\t['brian.redmond', '@', 'enron.com', ',', 'max.yzaguirre', '@', 'enron.com', ',', 'rob.milnthorp', '@', 'enron.com', 'Guys', ',', 'here', 'are', 'the', 'details', 'on', 'the', 'ESA', 'MEH', 'turbines', '-', 'please', 'forward', 'to', 'me', 'your', 'project', 'details', ',', 'economics', 'and', 'strategy', 'ASAP', '.', 'We', 'will', 'allocate', 'these', 'turbines', 'to', 'the', 'project', 'with', 'the', 'best', 'strategic/economic', 'rationale', 'once', 'confirming', 'that', 'they', 'are', 'worth', 'more', 'in', 'ENA', 'versus', 'ESA', '.', 'If', 'you', 'need', 'more', 'detailed', 'information', 'on', 'these', 'turbines', 'please', 'let', 'me', 'know', '.', 'Rob', ',', 'please', 'give', 'me', 'call', 'on', 'this', 'one', '.', 'TIME', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', 'Brett', 'R', 'Wiggs', '@', 'ENRON', 'DATE', 'TIME', 'The', 'attached', 'sheet', 'provides', 'a', 'summary', 'of', 'information', 'on', 'the', 'turbines', '.', 'David', 'W', 'Delainey', '@', 'ECT', 'DATE', 'TIME', 'Brett', ',', 'can', 'you', 'give', 'me', 'the', 'particulars', 'on', 'the', 'four', 'MEH', 'turbines', '(', 'ie', ')', 'scheduled', 'delivery', ',', 'price', ',', 'fuel', 'options', ',', 'heat', 'rate', ',', 'output', ',', 'etc', '-', 'including', 'transferablility', 'to', 'NA', '.']\n",
            "\t['christopher.calger', '@', 'enron.com', ',', 'wes.colwell', '@', 'enron.com', ',', 'janet.dietrich', '@', 'enron.com', ',', 'jeff.donahue', '@', 'enron.com', ',', 'w.duran', '@', 'enron.com', ',', 'mark.haedicke', '@', 'enron.com', ',', 'gary.hickerson', '@', 'enron.com', ',', 'mike.jakubik', '@', 'enron.com', ',', 'scott.josey', '@', 'enron.com', ',', 'john.lavorato', '@', 'enron.com', ',', 'rodney.malcolm', '@', 'enron.com', ',', 'george.mcclellan', '@', 'enron.com', ',', 'rob.milnthorp', '@', 'enron.com', ',', 'julia.murray', '@', 'enron.com', ',', 'jere.overdyke', '@', 'enron.com', ',', 'david.oxley', '@', 'enron.com', ',', 'kevin.presto', '@', 'enron.com', ',', 'brian.redmond', '@', 'enron.com', ',', 'jeffrey.shankman', '@', 'enron.com', ',', 'c.thompson', '@', 'enron.com', ',', 'max.yzaguirre', '@', 'enron.com', ',', 'james.ajello', '@', 'enron.com', ',', 'edward.ondarza', '@', 'enron.com', ',', 'vince.kaminski', '@', 'enron.com', ',', 'beth.perlman', '@', 'enron.com', ',', 'david.delainey', '@', 'enron.com', 'dan.leff', '@', 'enron.com', ',', 'mark.frevert', '@', 'enron.com', ',', 'patti.thompson', '@', 'enron.com', ',', 'catherine.dumont', '@', 'enron.com', ',', 'marsha.schiller', '@', 'enron.com', ',', 'mollie.gustafson', '@', 'enron.com', ',', 'shirley.tijerina', '@', 'enron.com', ',', 'christy.chapman', '@', 'enron.com', ',', 'tina.rode', '@', 'enron.com', ',', 'janette.elbertson', '@', 'enron.com', ',', 'stella.ely', '@', 'enron.com', ',', 'nicole.mayer', '@', 'enron.com', ',', 'tonai.lehr', '@', 'enron.com', ',', 'kimberly.hillis', '@', 'enron.com', ',', 'ana.alcantara', '@', 'enron.com', ',', 'yolanda.ford', '@', 'enron.com', ',', 'carolyn.george', '@', 'enron.com', ',', 'donna.baker', '@', 'enron.com', ',', 'rhonna.palmer', '@', 'enron.com', ',', 'felicia.doan', '@', 'enron.com', ',', 'katherine.benedict', '@', 'enron.com', ',', 'barbara.lewis', '@', 'enron.com', ',', 'pilar.cerezo', '@', 'enron.com', ',', 'terrellyn.parker', '@', 'enron.com', ',', 'dusty.paez', '@', 'enron.com', ',', 'shirley.crenshaw', '@', 'enron.com', ',', 'nicki.daw', '@', 'enron.com', ',', 'cherylene.westbrook', '@', 'enron.com', ',', 'kay.chapman', '@', 'enron.com', ',', 'cindy.skinner', '@', 'enron.com', ',', 'carol.moffett', '@', 'enron.com', ',', 'stacy.oravec', '@', 'enron.com', 'dan.leff', '@', 'enron.com', ',', 'mark.frevert', '@', 'enron.com', ',', 'patti.thompson', '@', 'enron.com', ',', 'catherine.dumont', '@', 'enron.com', ',', 'marsha.schiller', '@', 'enron.com', ',', 'mollie.gustafson', '@', 'enron.com', ',', 'shirley.tijerina', '@', 'enron.com', ',', 'christy.chapman', '@', 'enron.com', ',', 'tina.rode', '@', 'enron.com', ',', 'janette.elbertson', '@', 'enron.com', ',', 'stella.ely', '@', 'enron.com', ',', 'nicole.mayer', '@', 'enron.com', ',', 'tonai.lehr', '@', 'enron.com', ',', 'kimberly.hillis', '@', 'enron.com', ',', 'ana.alcantara', '@', 'enron.com', ',', 'yolanda.ford', '@', 'enron.com', ',', 'carolyn.george', '@', 'enron.com', ',', 'donna.baker', '@', 'enron.com', ',', 'rhonna.palmer', '@', 'enron.com', ',', 'felicia.doan', '@', 'enron.com', ',', 'katherine.benedict', '@', 'enron.com', ',', 'barbara.lewis', '@', 'enron.com', ',', 'pilar.cerezo', '@', 'enron.com', ',', 'terrellyn.parker', '@', 'enron.com', ',', 'dusty.paez', '@', 'enron.com', ',', 'shirley.crenshaw', '@', 'enron.com', ',', 'nicki.daw', '@', 'enron.com', ',', 'cherylene.westbrook', '@', 'enron.com', ',', 'kay.chapman', '@', 'enron.com', ',', 'cindy.skinner', '@', 'enron.com', ',', 'carol.moffett', '@', 'enron.com', ',', 'stacy.oravec', '@', 'enron.com', 'As', 'we', 'move', 'into', 'the', 'Spring/Summer', 'of', '2000', ',', 'it', 'is', 'time', 'to', 'turn', 'our', 'attention=', '=20', 'to', 'the', 'performance', 'review', 'process', '.', 'Mid-year', 'is', 'always', 'busy', 'and', 'we', 'have', 'a=', '=20', 'number', 'of', 'important', 'tasks', 'and', 'projects', 'in', 'process', '.', 'While', 'recognizing', 'this', ',', '=', '=20', 'it', 'remains', 'extremely', 'important', 'to', 'take', 'time', 'over', 'the', 'next', 'few', 'weeks', 'to', 'gath=', 'er=20', 'necessary', 'information', 'to', 'provide', 'quality', 'and', 'meaningful', 'feedback', 'for', 'our=20', 'employees', ',', 'as', 'well', 'as', 'utilize', 'this', 'information', 'during', 'the', 'year', 'end', 'review=', '=20', 'process', '.', 'In', 'the', 'spirit', 'of', 'One', 'Enron', ',', 'the', 'Performance', 'Review', 'Process', '(', 'PRC', ')', 'will', 'be=20', 'global', 'for', 'Mid-year', '2000', '.', 'Vice', 'Presidents', 'and', 'above', 'across', 'all', 'operating=', '=20', 'companies', 'will', 'be', 'reviewed', 'and', 'discussed', 'in', 'a', 'consistent', 'manner', 'with=20', 'identical', 'criteria', '.', 'ENA', 'will', 'review', 'all', 'professional', 'level', 'and', 'above=20', 'employees', '.', 'The', 'timeline', 'and', 'training', 'for', 'the', 'midyear', 'process', 'are', 'outlined', '=', 'at=20', 'the', 'end', 'of', 'this', 'memo', '.', 'Your', 'HR', 'Business', 'Consultant', 'is', 'also', 'available', 'to=20', 'answer', 'questions', '.', 'With', 'regards', 'to', 'the', 'Global', 'Functions', ',', 'review', 'sessions', 'will', 'be', 'led', 'by', 'the=20', 'Global', 'and/or', 'Corporate', 'Functional', 'heads', ',', 'and', 'will', 'be', 'designed', 'to', 'calibrate=', '=20', 'personnel', 'within', 'these', 'areas', 'of', 'expertise', '.', 'The', 'Global', 'Functional', 'Review=20', 'Areas', 'include', ':', '_', 'NetWorks/Technology', '_', 'Human', 'Resources', '_', 'Public', 'Relations', '&', 'Reg', 'Affairs=09G', '.', 'Whalley', '=09R', '.', 'Causey', '=09R', '.', 'Buy', '=09A', '.', 'Fastow', '=09C', '.', 'Olson', '=09S', '.', 'Kean', '=20', 'ENA', 'Mid-Year', 'Process', ':', 'ENA', 'has', 'received', 'favorable', 'feedback', 'on', 'the', 'review', 'process', 'used', 'for', 'Mid-year=', '=20', 'and', 'Year-end', '1999', ',', 'and', 'as', 'such', ',', 'will', 'follow', 'the', 'same', 'general', 'guidelines', 'and=', '=20', 'process', 'for', 'Mid-year', '2000', '.', 'The', 'following', 'are', 'key', 'features', 'of', 'the', 'Mid-year=', '=20', '2000', 'process', ':', 'o', 'The', 'focus', 'of', 'the', 'feedback', 'will', 'continue', 'to', 'be', 'on', 'the', 'qualitative', 'aspects', ',', '=', '=20', 'as', 'opposed', 'to', 'quantitative', '.', 'Toward', 'this', 'end', ',', 'communication', 'of', 'the', 'employee=', '=01', ',', 's=20', 'explicit', 'ranking', 'will', 'be', 'left', 'to', 'the', 'discretion', 'of', 'the', 'business', 'unit', 'manage=', 'r.', 'o', 'Initial', 'discussions', 'with', 'employees', 'regarding', 'their', 'accomplishments', ',', 'are=', '=20', 'highly', 'encouraged', ',', 'prior', 'to', 'the', 'Business', 'Review', 'Meetings', '.', 'o', 'Mid-year', 'performance', 'results', 'will', 'be', 'used', 'as', 'baseline', 'performance=20', 'information', 'for', 'Year-end', '2000.', 'o', 'Creation', 'of', '3', 'standard', 'feedback', 'forms', 'for', 'all', 'peer', 'groups', '.', '=20', 'o', 'Standardization', 'of', 'criteria', 'for', 'all', 'peer', 'groups', '.', 'o', 'Utilization', 'of', 'a', 'consistent', '6', 'gradation', 'rating', 'scale', '.', '=20', 'o', 'All', 'exempt', 'employees', 'will', 'be', 'discussed', 'at', 'Business', 'Review', 'Meetings', 'and=20', 'placed', 'into', 'one', 'of', 'six', 'categories', 'by', 'peer', 'group', '.', 'ENA', 'VP', \"'s\", 'will', 'be', 'pre-rank=', 'ed=20', 'by', 'the', 'ENA', 'Office', 'of', 'the', 'Chairman', 'and', 'Managing', 'Directors', 'prior', 'to', 'the', 'Enron=', '=20', 'PRC', '.', 'Non-exempt', '(', 'overtime', 'eligible', ')', 'employees', 'will', 'be', 'evaluated', 'by', 'their=', '=20', 'supervisors', 'and', 'placed', 'into', 'one', 'of', 'the', '6', 'categories', '.', 'The', 'results', 'of', 'the=20', 'Business', 'Review', 'Meetings', 'will', 'be', 'the', 'final', 'rankings', 'for', 'exempt', 'employees=20', 'below', 'VP', ',', 'subject', 'to', 'ENA', 'Office', 'of', 'the', 'Chairman', '.', 'o', 'A', 'minimum', 'of', 'two', 'representatives', 'from', 'other', 'functional', 'areas', 'will', 'be=20', 'required', 'at', 'the', 'Business', 'Review', 'Meetings', '.', 'The', 'meetings', 'should', 'otherwise', 'be=', '=20', 'rescheduled', 'to', 'allow', 'this', 'very', 'important', 'representation', 'to', 'take', 'place', '.', 'The=', '=20', 'nominated', 'individuals', 'are', 'illustrated', 'below', '.', 'o', 'The', 'top', '5', 'HR', 'priorities/challenges', 'for', '2000', 'should', 'also', 'be', 'agreed', 'to', 'at', 't=', 'he=20', 'Business', 'Review', 'Meetings', '.', 'o', 'Analysts', 'and', 'Associates', 'will', 'be', 'pre-reviewed', 'in', 'a', 'Business', 'Review', 'Meeting=', 's=20', 'based', 'on', 'their', 'current', 'rotation', ',', 'then', 'cross-calibrated', 'at', 'the', 'Enron', 'Global=', '=20', 'Analyst', 'and', 'Associate', 'Business', 'Review', 'Meeting', '.', 'Peer', 'Groups', ':', 'Commercial', 'Support', 'Specialized', 'Technical', 'Performance', 'Criteria', '(', 'for', 'all', 'peer', 'groups', ')', ':', 'Innovation/Entrepreneurship', 'Communication/Setting', 'Direction', 'Teamwork/Interpersonal', 'Leadership/Vision/Values=20', 'Analytical/Technical', 'o', 'Use', 'of', 'multiple', 'sources', 'of', 'input', 'is', 'encouraged', '(', 'employee', ',', 'peers', ',', 'direct=', '=20', 'reports', ',', 'internal', 'customers', ',', 'external', 'customers', ')', ',', 'as', 'is', 'a', 'self-evaluation', 'o', 'Employees', 'should', 'recommend', '5-10', 'reviewers', 'to', 'Supervisor', 'and', 'Supervisor=20', 'should', 'select', 'at', 'least', 'three', 'of', 'the', 'employee=01', ',', 's', 'recommendations', 'o', 'All', 'feedback', 'must', 'be', 'entered', 'via', 'the', 'Performance', 'Management', 'System', 'locate=', 'd=20', 'on', 'the', 'intranet', 'o', 'Supervisor', 'should', 'consolidate', 'the', 'feedback', ',', 'prepare', 'a', 'draft', 'of', 'the=20', 'Performance', 'Review', 'form', 'and', 'meet', 'with', 'the', 'employee', 'prior', 'to', 'the', 'Business=20', 'o', 'Final', 'feedback', 'to', 'exempt', 'employee', 'follows', 'the', 'July', '28th', 'meeting', 'o', 'For', 'VP', \"'s\", '&', 'MD', \"'s\", ',', 'final', 'feedback', 'follows', 'the', 'Enron', 'Executive', 'Committee=20', 'Business', 'Review', 'Meetings', '/', 'VP', 'Pre-Ranking', 'Committee', 'Meeting=20', 'Responsibilities', '/', 'Actions', ':', 'The', 'following', 'list', 'represents', 'suggested', 'groups', 'and', 'the', 'individuals=20', 'responsible', 'for', 'each', 'Business', 'Review', 'Meeting', '.', 'Attendees', 'at', 'the', 'meetings', 'ar=', 'e=20', 'appropriate', 'Supervisors', 'within', 'the', 'Business', 'Unit', '.', 'In', 'addition', ',', 'the', 'Office', '=', 'of=20', 'the', 'Chairman', 'requires', 'the', 'attendance', 'of', 'two', 'to', 'three', 'other', 'senior', 'level=20', 'representatives', 'from', 'other', 'Business', 'Units', 'to', 'add', 'external', 'perspective', '.', 'Area/Function=09ENA', 'Lead=09Global/Functional', 'Lead', '*', '=09Required', 'Non-functiona=', 'l', 'Attendees', '=09=09=09', 'COMMERCIAL=09=09=09', '=09=09=09', 'Trading=09Presto=09=09Dietrich', '=09Shankman=09=09Calger', '=09Lavorato=09=09Bowen', '=09McClellan=09=09Ajello', '=09Hickerson=09=09Delainey', '=09Belden=09=09', '=09=09=09', 'Origination=09Redmond=09=09Shankman', '=09Dietrich=09=09McClellan', '=09Milnthorp=09=09Belden', '=09Calger=09=09Presto', '=09Donahue=09=09Delainey', '=09Bowen=09=09Lavorato', '=09Ajello=09=09', '=09Duran=09=09', '=09Ondarza=09=09', '=09Malcolm=09=09', '=09Overdyke=09=09', '=09Thompson/Josey=09=09', '=09Yzaguirre=09=09', '=09=09=09', 'Finance', '(', '*', ')', '=09Jakubik=09Fastow=09', '=09=09=09', 'COMMERCIAL', 'SUPPORT=09=09=09', 'TECHNICAL', '=09=09=09', 'SPECIALIZED', 'TECHNICAL=09=09=09', '=09=09=09', 'Legal=09Haedicke=09=09', 'Research=09Kaminski=09=09', 'RAC=09Buy=09=09', 'Technical=09Miller/Parquet=09=09', '=09=09=09', 'Energy', 'Operations', '(', '*', ')', '=09Beck=09Causey=09Colwell', '=09=09=09Oxley', '=09=09=09', 'Business', 'Analysis', '&', 'Reporting/Tax', '(', '*', ')', '=09Colwell=09Causey=09Beck', '=09Mintz=09=09', '=09=09=09', 'Human', 'Resources', '(', '*', ')', '=09Oxley=09Olson=09', '=09=09=09', 'Public', 'Relations', '(', '*', ')', '=09Palmer=09Kean=09', '=09=09=09', 'NetWorks/Technology', '(', '*', ')', '=09Perlman=09Whalley/McConnell=09', '(', '*', ')', 'Note', ':', 'Global', 'Functional', 'Review', 'meetings', 'to', 'be', 'held', 'for', 'these', 'areas', '.', 'ENA', 'VP', 'Pre-Ranking', 'Committee', ':', 'Ray', 'Bowen=09Mark', 'Frevert=09Dan', 'Leff', '(', 'non', 'ENA', 'rep', ')', '=09David', 'Oxley', 'Dave', 'Delainey=09Brian', 'Redmond=09George', 'McClellan=09Mark', 'Haedicke', 'Janet', 'Dietrich=09Julia', 'Murray=09Jeff', 'Shankman=09Gary', 'Hickerson', 'Jeff', 'Donahue=09Jere', 'Overdyke=09Marty', 'Sunde', '(', 'non', 'ENA', 'rep', ')', '=09John', 'Lavorato', 'Outcomes', 'of', 'Business', 'Review', 'Meetings/', 'VP', 'Pre-Ranking', 'Committee', 'Meetings', ':', 'o', 'Calibration', 'of', 'employees', 'into', 'six', 'gradations=20', 'o', 'Promotion', 'nominations', 'below', 'VP', 'o', 'Assessment', 'of', 'the', '=01', '&', 'right', 'people', 'in', 'the', 'right', 'jobs=018', 'o', 'Assessment', 'of', 'gaps', 'for', 'what', 'is', 'needed', 'in', 'the', 'Business', 'Unit', '(', 'skills', ',', '=20', 'capabilities', ',', 'training', ',', 'experience', ')', 'o', 'Top', 'five', 'HR', 'challenges', 'o', 'Feedback', 'to', 'employees', 'on', 'the', 'results', 'of', 'the', 'meetings', ',', 'as', 'applicable', 'PEP', 'System', 'Open', 'for', 'Feedback', 'May', '17=20', 'PEP', 'System', 'Closes', 'for', 'Feedback', 'June', '9=20', 'Feedback', 'Collection/Initial', 'Employee', 'May', '17-June', '12', 'Discussions', '=20', 'Global', 'Functional', 'Review', 'Meetings', 'June', '12-June', '16', 'ENA', 'Business', 'Review', 'Meetings', 'June', '12-July', '25', 'ENA', 'VP', 'Pre-Ranking', 'Committee', 'Meeting', 'July', '28', 'Enron', 'Executive', 'Committee', 'meeting', 'July', '31-Aug.', '1']\n",
            "fossum-d\n",
            "\t['Dammit', 'Jenkins', ',', 'do', \"n't\", 'even', 'joke', 'about', 'stuff', 'like', 'that', '!', 'If', 'the', 'market', 'ever', 'realized', 'that', 'I', 'worked', 'here', ',', 'the', 'stock', 'would', 'go', 'down', '$', '10', '!', '!', '!', 'You', 'think', 'Lay', 'is', 'taking', 'the', 'first', 'step', 'toward', 'Sec', '.', 'Treas', '.', 'in', 'the', 'new', 'Bush', 'admin', '?', '?', '?', 'That', \"'s\", 'the', 'rumor', 'I', 'heard', 'a', 'month', 'ago', '.', 'Hope', 'all', 'goes', 'well', 'for', 'you', 'in', 'sunny', 'hotlanta', '.', 'Its', '5', 'below', 'zero', 'here', 'today', 'so', 'your', 'whole', 'Georgia', 'good', 'ole', \"'\", 'boy', 'lifestyle', 'thing', 'sounds', 'pretty', 'attractive', '.', 'AMF', 'DF', \"''\", 'Alan', 'Jenkins', \"''\", '<', 'ajenkins', '@', 'lanlaw.com', '>', 'on', 'DATE', 'TIME', 'I', 'trust', 'you', 'guys', 'saw', 'this', 'on', 'the', 'wires', 'today', ':', 'Enron', \"'s\", 'stock', 'was', 'off', '$', '3-3/16', 'or', '4.1', 'percent', 'in', 'afternoon', 'trading', 'at', '$', '74', ',', 'following', 'an', 'announcement', 'that', 'Jeff', 'Skilling', 'will', 'become', 'its', 'new', 'chief', 'executive', 'officer', 'on', 'Feb.', '12', '.', 'An', 'analyst', ',', 'who', 'asked', 'not', 'to', 'be', 'named', ',', 'said', 'that', 'it', 'had', 'been', 'widely', 'assumed', 'that', 'Drew', 'Fossum', 'would', 'be', 'named', 'CEO', ';', 'therefore', ',', 'the', 'company', \"'s\", 'stock', 'traded', 'lower', 'on', 'the', 'news', '.']\n",
            "\t['Thanks', '--', 'I', \"'ll\", 'pass', 'that', 'info', 'on', 'to', 'the', 'employment', 'guys', '.', 'df', 'A', 'friend', 'of', 'a', 'friend', '(', 'Petula', 'Workman', ')', 'is', 'looking', 'for', 'a', 'part', 'time', 'legal', 'position', '.', 'She', 'is', 'a', 'great', 'lawyer', '--', 'was', 'on', 'law', 'review', ',', 'people', 'who', 'worked', 'with', 'her', 'love', 'her', ',', 'but', 'she', 'just', 'wants', 'a', 'part', 'time', 'gig', 'since', 'she', 'is', 'a', 'mom', 'with', 'kid', 'responsibilities', '.', 'She', 'wants', 'to', 'work', 'part-time', '(', '20-24', 'hours/week', ')', 'preferably', 'employment', 'litigation', ',', 'but', 'commercial', 'litigation', 'would', 'work', 'too', '.', 'If', 'you', 'have', 'need', 'or', 'know', 'of', 'someone', 'who', 'does', ',', 'let', 'me', 'know', 'and', 'I', \"'ll\", 'get', 'her', 'resume', 'for', 'you', '.']\n",
            "arnold-j\n",
            "\t['saw', 'a', 'lot', 'of', 'the', 'bulls', 'sell', 'summer', 'against', 'length', 'in', 'front', 'to', 'mitigate', 'margins/absolute', 'position', 'limits/var', '.', 'as', 'these', 'guys', 'are', 'taking', 'off', 'the', 'front', ',', 'they', 'are', 'also', 'buying', 'back', 'summer', '.', 'el', 'paso', 'large', 'buyer', 'of', 'next', 'winter', 'today', 'taking', 'off', 'spreads', '.', 'certainly', 'a', 'reason', 'why', 'the', 'spreads', 'were', 'so', 'strong', 'on', 'the', 'way', 'up', 'and', 'such', 'a', 'piece', 'now', '.', 'really', 'the', 'only', 'one', 'left', 'with', 'any', 'risk', 'premium', 'built', 'in', 'is', 'h/j', 'now', '.', 'it', 'was', 'trading', 'equivalent', 'of', '180', 'on', 'access', ',', 'down', '40+', 'from', 'this', 'morning', '.', 'certainly', 'if', 'we', 'are', 'entering', 'a', 'period', 'of', 'bearish', 'to', 'neutral', 'trade', ',', 'h/j', 'will', 'get', 'whacked', '.', 'certainly', 'understand', 'the', 'arguments', 'for', 'h/j', '.', 'if', 'h', 'settles', '$', '20', ',', 'that', 'spread', 'is', 'probably', 'worth', '$', '10', '.', 'H', '20', 'call', 'was', 'trading', 'for', '55', 'on', 'monday', '.', 'today', 'it', 'was', '10/17', '.', 'the', 'market', \"'s\", 'view', 'of', 'probability', 'of', 'h', 'going', 'crazy', 'has', 'certainly', 'changed', 'in', 'past', '48', 'hours', 'and', 'that', 'has', 'to', 'be', 'reflected', 'in', 'h/j', '.', 'slafontaine', '@', 'globalp.com', 'on', 'DATE', 'TIME', 'mkt', 'getting', 'a', 'little', 'more', 'bearish', 'the', 'back', 'of', 'winter', 'i', 'think-if', 'we', 'get', 'another', 'cold', 'blast', 'jan/feb', 'mite', 'move', 'out', '.', 'with', 'oil', 'moving', 'down', 'and', 'march', 'closer', 'flat', 'wide', 'to', 'jan', 'im', 'not', 'so', 'bearish', 'these', 'sprds', 'now-less', 'bullish', 'march', 'april', 'as', 'well', '.']\n",
            "\t['Just', 'an', 'update', ':', 'Today', 'I', 'set', 'up', 'a', 'front', 'month', 'fixed', 'price', 'gas', 'daily', 'product', 'priced', 'at', 'parity', 'to', 'NYMEX', '.', 'I', 'thought', 'the', 'response', 'was', 'tremendous', '.', 'It', 'really', 'shows', 'that', 'we', 'might', 'have', 'an', 'angle', 'to', 'put', 'out', 'more', 'of', 'the', 'curve', 'and', 'become', 'the', 'predominant', 'benchmark', 'for', 'the', 'industry', 'rather', 'than', 'the', 'exchange', '.', 'One', 'problem', 'I', 'had', 'was', 'linking', '2', 'syncopated', 'basis', 'products', '.', 'I', 'set', 'up', 'a', 'new', 'product', 'for', 'the', 'prompt', 'that', 'was', 'Nov', 'GD/D', 'Henry', 'Hub', 'that', 'was', 'a', 'syncopated', 'basis', 'of', '0/0', 'to', 'the', 'Nov', 'Nymex', '.', 'However', ',', 'since', 'Dec', 'Nymex', 'is', 'a', 'syncopated', 'basis', 'to', 'Nov', 'Nymex', ',', 'I', 'could', 'not', 'set', 'up', 'a', 'syncopated', 'basis', 'link', 'around', 'the', 'Dec', 'Nymex', '.', 'Any', 'ideas', '?']\n",
            "beck-s\n",
            "\t['Thanks', 'for', 'rounding', 'up', 'the', 'tickets', 'for', 'the', 'Orange', 'Bowl', '.', 'You', 'can', 'mail', 'them', 'to', 'me', ',', 'or', 'just', 'hold', 'them', 'until', 'I', 'see', 'you', 'after', 'Christmas', '.', 'Mike', \"'s\", 'wife', 'decided', 'not', 'to', 'make', 'the', 'trip', ',', 'so', 'he', 'wo', \"n't\", 'be', 'using', 'the', 'tickets', '.', 'Jody', 'Crook', 'will', 'use', 'the', 'other', 'two', 'tickets', '.', 'Lunch', 'during', 'the', 'week', 'between', 'Christmas', 'and', 'New', 'Years', 'sounds', 'great', 'to', 'me', '.', 'I', 'will', 'be', 'working', 'that', 'week', ',', 'but', 'would', 'be', 'glad', 'to', 'meet', 'you', 'guys', 'at', 'Champions', 'for', 'lunch', 'if', 'that', 'is', 'best', '.', 'Or', 'if', 'you', 'are', 'game', 'for', 'Irma', \"'s\", ',', 'just', 'let', 'me', 'know', 'when', 'you', 'would', 'like', 'to', 'come', 'downtown', '.', '--', 'Sally', \"''\", 'Jacobs', ',', 'Ted', 'K', \"''\", '<', 'tjacobs', '@', 'ou.edu', '>', 'on', 'DATE', 'TIME', '<', 'mmcconn2', '@', 'ect.enron.com', '>', 'Sally/Mike', ',', 'I', 'will', 'be', 'in', 'Houston', 'the', 'week', 'after', 'Christmas', '(', '12/26-12/29', ')', 'and', 'was', 'wondering', 'if', 'the', 'two', 'of', 'you', 'were', 'going', 'to', 'be', 'in', 'the', 'office', ',', 'and', 'if', 'so', ',', 'would', 'you', 'be', 'available', 'for', 'lunch', '?', 'In', 'talking', 'with', 'David', 'Beck', ',', 'he', 'was', 'going', 'to', 'try', 'to', 'arrange', 'a', 'golf', 'game', '(', 'Mike', ',', 'me', ',', 'Richard', 'Kimberlin', 'and', 'David', ')', 'one', 'of', 'those', 'afternoons', 'at', 'Champions', '.', 'If', 'that', 'is', 'possible', ',', 'then', 'maybe', 'lunch', 'before', 'golf', 'might', 'work', '.', 'If', 'not', ',', 'then', 'I', 'can', 'meet', 'you', 'downtown', 'when', 'convenient', '.', 'Let', 'me', 'know', 'what', 'your', 'schedules', 'are', 'like', 'and', 'I', 'will', 'plan', 'my', 'schedule', 'accordingly', '.', 'Also', ',', 'I', 'need', 'to', 'know', 'if', 'I', 'need', 'to', 'mail', 'the', 'Orange', 'Bowl', 'tickets', 'to', 'both', 'of', 'you', 'separately', 'or', 'just', 'one', 'of', 'you', '.', 'Did', \"n't\", 'know', 'if', 'you', 'are', 'planning', 'on', 'going', 'to', 'Miami', 'together', '?', 'I', 'should', 'receive', 'the', 'tickets', 'in', 'the', 'next', 'day', 'or', 'two', 'and', 'will', 'do', 'whatever', '.', 'Ought', 'to', 'be', 'a', 'fun', 'trip', ',', 'as', 'it', 'has', 'definitely', 'been', 'awhile', 'since', 'the', 'Sooners', 'have', 'been', 'to', 'Miami', '.', 'Anyway', ',', 'let', 'me', 'know', 'if', 'you', 'are', 'available', 'for', 'lunch/gold', 'or', 'just', 'lunch', '.', 'Hope', 'you', 'all', 'have', 'a', 'wonderful', 'holiday', 'season', 'and', 'most', 'of', 'all', 'get', 'to', 'spend', 'time', 'with', 'your', 'families', '!', 'Ted', 'K.', 'Jacobs', 'Director', 'Energy', 'Management', 'The', 'University', 'of', 'Oklahoma', '307', 'West', 'Brooks', ',', 'Room', '218', 'Norman', ',', 'OK', '73019-4007', '(', '405', ')', '325-0758', '(', '405', ')', '325-2096', 'fax', '-', 'C.DTF']\n",
            "\t['The', 'week', 'of', 'November', '13', 'is', 'the', 'week', 'of', 'the', 'Enron', 'Management', 'Conference', 'in', 'San', 'Antonio', '.', 'It', 'begins', 'on', 'Wednesday', 'evening', ',', 'so', 'most', 'people', 'will', 'be', 'travelling', 'on', 'Wednesday', 'afternoon', '.', 'I', 'will', 'be', 'in', 'the', 'office', 'on', 'Monday', 'and', 'Tuesday', 'that', 'week', ',', 'so', 'those', 'days', 'work', 'well', 'for', 'me', 'for', 'your', 'visit', '.', 'I', 'just', 'wanted', 'you', 'to', 'know', 'about', 'the', 'conference', 'in', 'case', 'that', 'has', 'an', 'impact', 'on', 'other', 'meetings', 'that', 'you', 'might', 'want', 'to', 'have', 'in', 'Houston', 'that', 'week', '.', 'Let', 'me', 'know', '.', 'I', 'will', 'look', 'forward', 'to', 'seeing', 'you', 'and', 'introducing', 'you', 'to', 'others', 'on', 'the', 'team', '.', 'We', 'are', 'looking', 'forward', 'to', 'seeing', 'Mo', 'next', 'week', 'here', 'in', 'Houston', '.', 'Have', 'a', 'great', 'weekend', '.', '--', 'Sally', 'DATE', 'TIME', 'Hi', 'there', '--', '-', 'Had', 'lunch', 'with', 'Mo', 'today', '--', 'so', 'as', 'you', 'can', 'imagine', 'she', 'was', 'very', 'interested', 'in', 'my', 'new', 'role', ',', 'working', 'with', 'you', '.', 'Fernley', 'has', 'decided', 'that', 'it', 'is', 'too', 'hard', 'to', 'write', 'down', 'all', 'of', 'the', 'organizational', 'changes', 'and', 'how', 'it', 'affects', 'all', 'of', 'the', 'people', 'who', 'reported', 'in', 'to', 'Phillip', 'and', 'I', ',', 'so', 'he', 'has', 'just', 'verbally', 'announced', 'the', 'changes', '.', 'But', ',', 'at', 'any', 'rate', ',', 'the', 'word', 'is', 'getting', 'out', '.', 'I', 'had', \"n't\", 'seen', 'Mo', 'in', 'months', ',', 'so', 'it', 'was', 'good', 'to', 'catch', 'up', '.', 'I', 'think', 'she', 'is', 'headed', 'to', 'Houston', 'this', 'week', '(', 'so', 'is', 'Frank', ')', 'so', 'I', 'am', 'sure', 'you', 'will', 'be', 'hearing', 'from', 'her', '.', 'I', 'have', 'tentatively', 'blocked', 'out', 'the', 'week', 'beginning', 'Monday', ',', 'Nov.', '13th', 'to', 'come', 'over', 'to', 'Houston', ',', 'and', 'would', 'like', 'to', 'spend', 'some', 'of', 'that', 'time', 'with', 'you', 'and', 'your', 'team', ',', 'meeting', 'people', ',', 'and', 'maybe', 'just', 'following', 'you', 'around', 'for', 'the', 'day', ',', 'as', 'you', 'suggested', '.', 'Does', 'that', 'week', 'work', 'for', 'you', '?', 'I', 'think', 'the', 'Management', 'conference', 'is', 'later', 'in', 'the', 'month', ',', 'so', 'people', 'will', 'generally', 'be', 'around', '.', 'Please', 'let', 'me', 'know', ',', 'and', 'I', 'will', 'make', 'sure', 'it', 'happens', '.', 'I', 'will', 'also', 'need', 'to', 'spend', 'some', 'time', 'with', 'Melissa', 'Becker', 'and', 'her', 'team', 'working', 'on', 'Post', 'ASE', 'Reporting', 'solutions', ',', 'but', 'will', 'plan', 'to', 'spend', 'a', 'significant', 'amount', 'of', 'time', 'with', 'the', 'North', 'America', 'group', '.', 'What', 'do', 'you', 'think', '?', 'I', 'am', 'ready', 'to', 'get', 'moving', 'on', 'some', 'new', 'things', '!', '!', '!', '!']\n",
            "campbell-l\n",
            "\t['The', 'third', 'quarter', 'PCB', 'meeting', 'with', 'Southern', 'California', 'Gas', 'Company', 'was', 'held', 'this', 'morning', '.', 'SoCal', 'presented', 'a', 'third', 'quarter', 'invoce', 'of', 'their', 'PCB', 'management', 'and', 'disposal', 'activities', 'for', 'which', 'Transwestern', 'is', 'responsible', 'for', '$', '120,602.19', '.', 'All', 'charges', 'were', 'appropriate', 'and', 'considered', 'normal', 'operating', 'expenses', 'for', 'PCB', 'activities', 'in', 'California', '.', 'The', 'public', 'hearing', 'was', 'held', 'in', 'Williams', ',', 'AZ', 'for', 'the', 'Kingman', 'and', 'Flagstaff', 'air', 'permits', 'under', 'the', 'Redrok', 'Expansion', '.', 'There', 'were', 'no', 'comments', 'or', 'concerns', 'brought', 'up', 'at', 'the', 'meeting', 'as', 'no', 'individuals', 'came', 'to', 'the', 'meeting', '.', 'An', 'email', 'was', 'received', 'from', 'the', 'ADEQ', 'presenting', 'the', 'minor', 'additions', 'which', 'will', 'be', 'added', 'to', 'each', 'permit', '.', 'Each', 'comment', 'and', 'addition', 'will', 'not', 'impact', 'or', 'change', 'the', 'draft', 'permits', 'which', 'were', 'received', 'earlier', 'this', 'month', '.', 'The', 'permits', 'for', 'Klagetoh', 'and', 'Luepp', 'were', 'received', 'from', 'the', 'EPA', 'last', 'week', '.', 'The', 'permits', 'from', 'the', 'ADEQ', 'for', 'the', 'Kingman', 'and', 'Flagstaff', 'C/S', 'will', 'be', 'issued', 'the', 'later', 'part', 'of', 'this', 'week', '.', 'Attended', 'the', 'incident', 'investigation', 'and', 'technical', 'writing', 'workshop', 'in', 'Omaha', '.', 'Assisted', 'the', 'Mountainair', 'team', 'with', 'the', 'semiannual', 'Title', 'V', 'compliance', 'monitoring', 'report', 'for', 'C/S', 'No.7', '.', 'A', 'meeting', 'was', 'held', 'in', 'Phoenix', ',', 'Az', 'with', 'PG', '&', 'E', 'to', 'review', 'charges', 'and', 'invoices', 'by', 'PG', '&', 'E', 'for', 'PCB', 'management', 'and', 'disposal', 'activities', 'on', 'their', 'system', 'for', 'the', 'last', 'several', 'months', '.', 'Also', 'discussed', 'was', 'recent', 'liquids', 'sampling', 'results', 'and', 'proposed', 'PCB', 'activities', 'on', 'the', 'PG', '&', 'E', 'system', 'for', '2002', '.']\n",
            "\t['http', ':', '//quotes.freerealtime.com/rt/frt/news', '?', 'symbol=PMCS', '&', 'art=C2000090100245b1087']\n",
            "badeer-r\n",
            "\t['mitch.mcclintock', '@', 'enron.com', 'I', 'will', 'be', 'out', 'of', 'the', 'office', 'on', 'Friday', ',', 'Monday', 'and', 'Tuesday', 'for', 'vacation', '.', 'I', 'will', 'be', 'able', 'to', 'be', 'reached', 'by', 'cell', 'phone', 'if', 'necessary', '.']\n",
            "\t['what', 'is', 'your', 'fax', 'number', '?']\n",
            "brawner-s\n",
            "\t['``', 'Jon', 'Schnitzer', \"''\", '<', 'jons', '@', 'amerexenergy.com', '>', 'on', 'DATE', 'TIME', '>', '>', '>', '>', '>', 'A', 'priest', 'took', 'a', 'sebatacle', 'to', 'a', 'fishing', 'lodge', '.', 'On', 'the', 'last', 'day', 'of', '>', '>', '>', '>', 'trip', 'he', 'hooked', 'a', 'monster', 'fish', 'and', 'proceeded', 'to', 'reel', 'it', 'in', '.', 'The', '>', '>', '>', '>', 'holding', 'a', 'net', ',', 'yelled', '``', 'Look', 'at', 'the', 'size', 'of', 'that', 'Son', 'of', 'a', 'Bitch', '!', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', 'Son', ',', 'I', \"'m\", 'a', 'priest', '.', 'Your', 'language', 'is', 'uncalled', 'for', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'No', ',', 'Father', ',', 'that', \"'s\", 'what', 'kind', 'of', 'fish', 'it', 'is', '.', 'A', 'Son', 'of', 'a', 'Bitch', 'fish', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Really', '?', 'Well', 'help', 'me', 'land', 'this', 'Son', 'of', 'a', 'Bitch', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Once', 'in', 'the', 'boat', ',', 'they', 'marveled', 'at', 'the', 'monster', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Father', ',', 'that', 'is', 'the', 'biggest', 'Son', 'of', 'a', 'Bitch', 'I', \"'ve\", 'ever', 'seen', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Yes', ',', 'my', 'Son', ',', 'it', 'is', 'a', 'big', 'Son', 'of', 'a', 'Bitch', '.', 'What', 'should', 'I', 'do', 'with', 'it', '?', '>', '>', '>', '>', '>', '>', '>', '>', 'Why', 'eat', 'it', 'of', 'course', '.', 'You', \"'ve\", 'never', 'tasted', 'anything', 'as', 'good', 'as', 'that', '>', '>', 'Son', '>', '>', '>', '>', 'of', 'a', 'Bitch', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Elated', ',', 'the', 'priest', 'headed', 'home', 'to', 'the', 'church', '.', 'While', 'unloading', 'his', '>', '>', 'gear', ',', '>', '>', '>', '>', 'and', 'his', 'prize', 'catch', ',', 'Sister', 'Mary', 'inquired', 'about', 'his', 'trip', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Take', 'a', 'look', 'at', 'this', 'big', 'Son', 'of', 'a', 'Bitch', 'I', 'caught', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Sister', 'Mary', 'gasped', 'and', 'clutchted', 'her', 'rosary', ',', '``', 'Father', '!', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', 'It', \"'s\", 'ok', 'Sister', '.', 'That', \"'s\", 'what', 'kind', 'of', 'fish', 'it', 'is', '.', 'A', 'Son', 'of', 'a', 'Bitch', '>', '>', 'fish', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Oh', ',', 'well', 'then', 'what', 'are', 'you', 'going', 'to', 'do', 'with', 'that', 'big', 'Son', 'of', 'a', 'Bitch', '?', '>', '>', '>', '>', '>', '>', '>', '>', 'Why', ',', 'eat', 'it', 'of', 'course', '.', 'The', 'guide', 'said', 'nothing', 'compares', 'to', 'the', 'taste', '>', '>', 'of', '>', '>', '>', 'a', '>', '>', '>', '>', 'Son', 'of', 'a', 'Bitch', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Sister', 'informed', 'the', 'priest', 'that', 'the', 'Pope', 'was', 'scheduled', 'to', 'visit', '>', '>', 'in', '>', '>', '>', 'a', '>', '>', '>', '>', 'few', 'days', 'and', 'that', 'they', 'should', 'fix', 'the', 'Son', 'of', 'a', 'Bitch', 'for', 'dinner', '.', '>', '>', \"''\", \"I'll\", '>', '>', '>', '>', 'even', 'clean', 'the', 'Son', 'of', 'a', 'Bitch', \"''\", ',', 'she', 'said', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'As', 'she', 'was', 'cleaning', 'the', 'huge', 'fish', ',', 'the', 'Friar', 'walked', 'in', '.', 'What', 'are', '>', '>', '>', '>', 'doing', 'Sister', '?', '>', '>', '>', '>', '>', '>', '>', '>', 'Father', 'wants', 'me', 'to', 'clean', 'this', 'big', 'Son', 'of', 'a', 'Bitch', 'for', 'the', \"Pope's\", '>', '>', 'dinner', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Sister', '!', 'I', \"'ll\", 'clean', 'it', 'if', 'you', \"'re\", 'so', 'upset', '!', 'Please', 'watch', 'your', 'language', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'No', ',', 'no', ',', 'no', '.', 'It', \"'s\", 'called', 'a', 'Son', 'of', 'a', 'Bitch', 'fish', '.', 'Really', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Oh', ',', 'well', 'in', 'that', 'case', 'I', \"'ll\", 'fix', 'up', 'a', 'great', 'meal', 'and', 'that', 'Son', 'of', 'a', '>', '>', 'Bitch', '>', '>', '>', '>', 'can', 'be', 'the', 'main', 'course', '!', 'Let', 'me', 'know', 'when', 'you', \"'ve\", 'finished', 'cleaning', '>', '>', 'that', '>', '>', '>', '>', 'Son', 'of', 'a', 'Bitch', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'On', 'the', 'night', 'of', 'the', 'Pope', \"'s\", 'visit', ',', 'everything', 'was', 'perfect', '.', 'The', 'Friar', '>', '>', 'had', '>', '>', '>', '>', 'prepared', 'an', 'excellent', 'meal', ',', 'there', 'was', 'wine', ',', 'and', 'the', 'fish', 'was', '>', '>', 'excellent', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Pope', 'said', ',', '``', 'This', 'is', 'great', 'fish', ',', 'where', 'did', 'you', 'get', 'it', '?', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', '``', 'I', 'caught', 'the', 'Son', 'of', 'a', 'Bitch', '!', \"''\", 'proclaimed', 'the', 'proud', 'priest', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Pope', \"'s\", 'eyes', 'opened', 'wide', ',', 'but', 'he', 'said', 'nothing', '.', '>', '>', '>', '>', '>', '>', '>', '>', '``', 'And', 'I', 'cleaned', 'the', 'Son', 'of', 'a', 'Bitch', '!', \"''\", 'exclaimed', 'the', 'sister', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Pope', 'sat', 'silent', 'in', 'disbelief', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'And', 'the', 'friar', 'added', ',', '``', 'And', 'I', 'prepared', 'the', 'Son', 'of', 'a', 'Bitch', ',', 'using', 'a', '>', '>', '>', 'special', '>', '>', '>', '>', 'recipe', '!', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Pope', 'looked', 'at', 'each', 'of', 'them', '.', 'Slowly', 'a', 'big', 'smile', 'creeped', 'across', '>', '>', 'his', '>', '>', '>', '>', 'face', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'You', 'fuckers', 'are', 'alright', '!', '!', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', '>', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '>', '>', 'This', 'email', 'and', 'any', 'files', 'transmitted', 'with', 'it', 'from', 'the', 'ElPaso', '>', '>', 'Corporation', 'are', 'confidential', 'and', 'intended', 'solely', 'for', 'the', '>', '>', 'use', 'of', 'the', 'individual', 'or', 'entity', 'to', 'whom', 'they', 'are', 'addressed', '.', '>', '>', 'If', 'you', 'have', 'received', 'this', 'email', 'in', 'error', 'please', 'notify', 'the', '>', '>', 'sender', '.', '>', '>', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '>', '>', '_________________________________________________________________', '>', 'Get', 'your', 'FREE', 'download', 'of', 'MSN', 'Explorer', 'at', 'http', ':', '//explorer.msn.com']\n",
            "\t['TIME', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', \"''\", 'susan', 'schnitzer', \"''\", '<', 's.schnitzer', '@', 'worldnet.att.net', '>', 'on', 'DATE', 'TIME', '--', '--', '-Original', 'Message', '--', '--', '-', '<', 'hanaone', '@', 'aol.com', '>', ';', 'bbron58584', '@', 'aol.com', '<', 'bbron58584', '@', 'aol.com', '>', ';', 'lcbron', '@', 'aol.com', '<', 'lcbron', '@', 'aol.com', '>', ';', 'giannini_sa', '@', 'williscorroon.com', '<', 'giannini_sa', '@', 'williscorroon.com', '>', ';', 'danielle.karwoski', '@', 'dowjones.com', '<', 'danielle.karwoski', '@', 'dowjones.com', '>', ';', 'skaszer', '@', 'hotmail.com', '<', 'skaszer', '@', 'hotmail.com', '>', ';', 'preventdk', '@', 'dellmail.com', '<', 'preventdk', '@', 'dellmail.com', '>', ';', 'leanne_michalek', '@', 'njb.uscourts.gov', '<', 'leanne_michalek', '@', 'njb.uscourts.gov', '>', ';', 'bposkitt', '@', 'sprintmail.com', '<', 'bposkitt', '@', 'sprintmail.com', '>', ';', 'kjposkitt', '@', 'aol.com', '<', 'kjposkitt', '@', 'aol.com', '>', ';', 'poskitt', '@', 'worldnet.att.net', '<', 'poskitt', '@', 'worldnet.att.net', '>', ';', 'msawatka', '@', 'hotmail.com', '<', 'msawatka', '@', 'hotmail.com', '>', ';', 's.schnitzer', '@', 'worldnet.att.net', '<', 's.schnitzer', '@', 'worldnet.att.net', '>', '>', '>', '>', '>', 'TIGHT', 'SKIRTS', 'AND', 'TEXANS', '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', 'In', 'a', 'crowded', 'city', 'at', 'a', 'crowded', 'bus', 'stop', ',', 'a', 'beautiful', '>', 'young', 'woman', 'was', 'waiting', 'for', 'the', 'bus', '.', 'She', 'was', 'decked', 'out', 'in', 'a', 'tight', '>', 'leather', 'mini', 'skirt', 'with', 'matching', 'tight', 'leather', 'boots', 'and', 'jacket', '.', '>', '>', 'As', 'the', 'bus', 'rolled', 'up', 'and', 'it', 'became', 'her', 'turn', 'to', 'get', 'on', ',', 'she', 'became', 'aware', '>', 'that', 'her', '>', 'skirt', 'was', 'too', 'tight', 'to', 'allow', 'her', 'leg', 'to', 'come', 'up', 'to', 'the', 'height', 'of', 'the', '>', 'first', 'step', 'on', 'the', '>', 'bus', '.', 'Slightly', 'embarrassed', ',', 'and', 'with', 'a', 'quick', 'smile', 'to', 'the', 'bus', '>', 'driver', ',', 'she', 'reached', 'behind', 'her', 'and', 'unzipped', 'her', 'skirt', 'a', 'little', ',', 'thinking', '>', 'that', 'this', 'would', 'give', 'her', 'enough', 'slack', 'to', 'raise', 'her', 'leg', '.', 'Again', 'she', 'tried', '>', 'to', 'make', 'the', 'step', 'on', 'to', 'the', 'bus', 'only', 'to', 'discover', 'she', 'still', '>', 'could', \"n't\", '.', '>', '>', 'So', ',', 'a', 'little', 'more', 'embarrassed', ',', 'she', 'once', 'again', 'reached', '>', 'behind', 'her', 'and', 'unzipped', 'her', 'skirt', 'a', 'little', 'more', 'and', ',', 'for', 'a', 'second', 'time', '>', 'attempted', 'the', 'step', '.', '>', 'Once', 'again', ',', 'much', 'to', 'her', 'chagrin', ',', 'she', 'could', 'not', 'raise', 'her', '>', 'leg', 'because', 'of', 'the', 'tight', 'skirt', '.', 'With', 'a', 'coy', 'little', 'smile', 'to', 'the', 'driver', ',', '>', 'she', '>', 'again', 'unzipped', 'the', 'offending', 'skirt', 'to', 'give', 'a', 'little', 'more', 'slack', 'and', 'again', '>', 'was', 'unable', 'to', 'make', 'the', 'step', '.', '>', '>', 'About', 'this', 'time', ',', 'the', 'big', 'Texan', 'behind', 'her', 'in', 'line', 'picked', '>', 'her', 'up', 'easily', 'from', 'the', 'waist', 'and', 'placed', 'her', 'lightly', 'on', 'the', 'top', 'step', 'of', '>', 'the', '>', '>', 'bus', '.', '>', 'She', 'went', 'absolutely', 'ballistic', 'and', 'turned', 'on', 'the', 'would-be', '>', 'hero', ',', 'screeching', 'at', 'him', '.', '``', 'How', 'dare', 'you', 'touch', 'my', 'body', '!', '!', '>', 'I', 'do', \"n't\", 'even', 'know', 'who', 'you', '>', 'are', '!', \"''\", '>', '>', 'At', 'this', ',', 'the', 'Texan', 'drawled', ',', '``', 'Well', \"Ma'am\", ',', 'normally', 'I', '>', 'would', 'agree', 'with', 'you', ',', 'but', 'after', 'you', 'unzipped', 'my', 'fly', 'three', 'times', ',', 'I', 'kinda', '>', 'figured', 'that', 'we', 'was', 'friends', '.', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', '________________________________________________', '>', 'Do', 'You', 'Yahoo', '!', '?', '>', 'Get', 'your', 'free', '@', 'yahoo.com', 'address', 'at', 'http', ':', '//mail.yahoo.com', '>', '>']\n",
            "carson-m\n",
            "\t['What', 'is', 'up', '?', '?', 'What', 'do', 'you', 'think', 'about', 'the', 'cotton', 'bowl', '?', '?', '?', 'Are', 'you', 'going', '?', '?']\n",
            "\t['TIME', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', \"''\", 'Pape', ',', 'Travis', \"''\", '<', 'tpape', '@', 'satake-usa.com', '>', 'on', 'DATE', 'TIME', 'And', 'it', 'is', 'on', '!', 'It', \"'s\", 'all', 'about', 'the', 'he', 'said', ',', 'she', 'said', 'bullshit', '--', '--', '-Original', 'Message', '--', '--', '-', 'Are', 'you', 'guys', 'up', 'for', 'a', 'little', 'guys', 'night', 'out', 'tonight', '?', '?', 'Call', 'me', '713-853-6203', 'or', 'leave', 'a', 'message', 'for', 'me', 'at', 'home', '713-668-3712', '.']\n",
            "farmer-d\n",
            "\t['Can', 'you', 'come', 'down', 'to', 'my', 'desk', 'around', '1:00', '?', 'Enron', 'North', 'America', 'Corp.', 'From', ':', 'Megan', 'Parker', '@', 'ENRON', 'DATE', 'TIME', 'Do', 'you', 'have', 'any', 'time', 'this', 'afternoon', 'or', 'Monday', 'to', 'look', 'at', 'the', 'Tenaska', 'spreadsheet', '?', 'I', 'am', 'trying', 'to', 'close', 'out', 'Jan', '2001', 'and', 'I', 'have', 'some', 'questions', '.']\n",
            "\t['Charlene', ',', 'We', 'should', 'not', 'have', 'scheduled', 'any', 'volume', 'for', 'the', '29-30th', '.', 'No', 'price', 'was', 'negotiated', 'that', 'I', 'can', 'find', '.', 'However', ',', 'since', 'gas', 'did', 'flow', ',', 'I', 'rolled', 'the', 'last', 'price', 'on', 'the', 'deal', 'to', 'cover', 'those', 'days', '.', 'What', 'price', 'is', 'Hesco', 'showing', '?', 'DATE', 'TIME', 'Daren', 'would', 'you', 'look', 'at', 'the', 'price', 'for', '29', 'and', '30th', 'of', 'March', '2000', '.', 'There', 'are', 'no', 'prices', 'for', 'these', 'days', 'but', 'volume', 'was', 'scheduled', 'for', 'these', 'days', '.', 'Daren', 'J', 'Farmer', 'DATE', 'TIME', 'Charlene', ',', 'Deal', '#', '214948', 'already', 'had', 'volume', 'and', 'price', 'for', 'the', '12th', 'and', '13th', '.', 'You', 'may', 'need', 'to', 'have', 'the', 'volumes', 'updated', 'by', 'Volume', 'Management', '.', 'I', 'added', 'the', '15th', 'and', '16th', 'to', 'the', 'deal', 'ticket', '.', 'DATE', 'TIME', 'Hakemack/HOU/ECT', '@', 'ECT', 'Help', '.', 'Steve', 'Mauch', 'at', 'Hesco', 'is', 'wanting', 'an', 'answer', 'ASAP', 'TIME', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', 'Vance', 'L', 'Taylor', 'DATE', 'TIME', 'This', 'gas', 'purchase', 'is', 'not', 'a', 'part', 'of', 'the', 'wellhead', 'portfolio', 'but', 'is', 'being', 'traded', 'on', 'the', 'Texas', 'desk', '.', 'I', 'would', 'suggest', 'you', 'get', 'with', 'Darren', 'Farmer', 'or', 'someone', 'on', 'the', 'desk', '.', 'Sorry', 'I', 'could', 'not', 'be', 'of', 'more', 'assistance', '!', 'x3-6353', 'DATE', 'TIME', 'Meter', '986725', 'for', 'March', '2000', '.', 'Per', 'Hesco', 'both', 'traders', 'are', 'gone', 'at', '(', 'Hesco', 'and', 'Enron', ')', 'and', 'they', '(', 'Hesco', ')', 'were', 'not', 'paid', 'the', 'correct', 'price', 'in', 'March', 'on', 'the', 'days', 'mentioned', 'below', '.', 'Hesco', 'can', 'not', 'find', 'where', 'the', 'price', 'for', 'these', 'days', 'were', 'recorded', '.', 'Per', 'Hesco', 'they', 'were', 'underpaid', 'by', '$', '32,101.57', '.', 'Hesco', 'is', 'wanting', 'to', 'come', 'to', 'our', 'office', 'to', 'have', 'a', 'meeting', 'about', 'clearing', 'this', 'up', '.', 'It', 'will', 'be', 'nice', 'if', 'we', 'do', \"n't\", 'have', 'to', 'meet', 'with', 'them', '.', 'Production', 'dates', 'are', 'Volume', 'price', 'they', 'are', 'looking', 'for', '03/12', '2,029', '2.65', '03/13', '2,009', '2.65', '03/15', '2,022', '2.71', '03/16', '1,976', '2.72']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove stopwords from emails\n",
        "eng_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "for author in project_authors:\n",
        "  tokenized_emails = authors_tokenized_emails[author]\n",
        "  for email_token_list in tokenized_emails:\n",
        "    for token in email_token_list:\n",
        "      if token in eng_stopwords:\n",
        "        email_token_list.remove(token)\n",
        "\n",
        "# DEBUG OUTPUT\n",
        "print(\"SAMPLE\")\n",
        "for author in project_authors:\n",
        "  print(author)\n",
        "  email_list = authors_tokenized_emails[author]\n",
        "  for email_tokens in email_list[0:2]:\n",
        "    print(f\"\\t{email_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_1SkPq19koF",
        "outputId": "412c63f8-737d-4280-b5d9-d8a377c3c6da"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE\n",
            "allen-p\n",
            "\t['Here', 'our', 'forecast']\n",
            "\t['You', 'wrote', 'fewer', 'checks', 'month', '.', 'Spent', 'money', 'Materials', 'less', 'Labor', '.', 'June', 'July', 'August', 'Total', 'Materials', '2929', '4085', '4801', 'Services', '53', '581', '464', 'Labor', '3187', '3428', '2770', 'Here', 'my', 'questions', 'August', 'bank', 'statement', '(', 'attached', ')', ':', '1', '.', 'Check', '1406', 'Walmart', 'Description', 'unit', '?', '2', '.', 'Check', '1410', 'Crumps', 'Detail', 'description', 'unit', '?', '3', '.', 'Check', '1411', 'Lucy', 'What', 'this', '?', '4', '.', 'Check', '1415', 'Papes', 'Detail', 'description', 'units', '?', '5', '.', 'Checks', '1416', ',', '1417', ',', '1425', 'Why', 'overtime', '?', '6', '.', 'Check', '1428', 'Ralph', \"'s\", 'What', 'unit', '?', '7', '.', 'Check', '1438', 'Walmart', '?', 'Description', 'unit', '?', 'Try', 'pull', 'together', 'the', 'support', 'these', 'items', 'get', 'back', 'me', '.']\n",
            "bass-e\n",
            "\t['From', ':', 'Larry', 'Joe', 'Hunter', 'DATE', 'TIME', 'Can', 'adjust', 'TAGG', 'shortname', 'MIRANTAMEENE', '(', 'currently', 'MIRANTAMEENECAN', ')', '?']\n",
            "\t[\"o'neal.winfree\", '@', 'enron.com', ',', 'bryan.hull', '@', 'enron.com', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', 'http', ':', '//www.altavista.com/cgi-bin/query', '?', 'pg=q', '&', 'sc=on', '&', 'q=register+domain', '&', 'kl=XX', '&', 'styp', 'e=stext']\n",
            "buy-r\n",
            "\t['ted.murphy', '@', 'enron.com', ',', 'mark.ruane', '@', 'enron.com', ',', 'steve.young', '@', 'enron.com', 'pam.metoyer', '@', 'enron.com', ',', 'rita.hennessy', '@', 'enron.com', ',', 'denise.naiser', '@', 'enron.com', ',', 'claire.dunnett', '@', 'enron.com', ',', 'veronica.valdez', '@', 'enron.com', 'pam.metoyer', '@', 'enron.com', ',', 'rita.hennessy', '@', 'enron.com', ',', 'denise.naiser', '@', 'enron.com', ',', 'claire.dunnett', '@', 'enron.com', ',', 'veronica.valdez', '@', 'enron.com', 'I', 'of', 'office', 'week', 'Christmas', 'New', 'Year', \"'s\", 'can', 'be', 'contacted', 'telephone', 'fax', '@', '(', '603', ')', '875-0794', '.', 'Please', 'make', 'certain', 'there', 'coverage', 'all', 'times', 'area', '.', 'Also', ',', 'please', 'send', 'Karen', 'your', 'own', 'schedule', '.']\n",
            "\t['fyi', ',', 'rick', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', 'John', 'L', 'Nowlan', 'DATE', 'TIME', 'McConnell/HOU/ECT', '@', 'ECT', 'Recognizing', 'below', 'daily', 'VAR', 'limits', 'today', ',', 'coupled', 'high', 'volatility', 'the', 'crude', 'products', 'markets', ',', 'attempted', 'do', 'interday', 'calc', '.', 'Unfortunately', 'took', 'us', 'time', 'get', 'the', 'right', 'person', 'succeed', 'getting', 'estimate', 'right', 'the', 'close', 'showed', 'we', 'were', 'near', 'limits', 'we', 'were', 'yesterday', '.', 'I', 'flag', 'up', 'point', 'it', 'critical', 'these', ',', 'markets', 'we', 'some', 'cover', 'know', 'we', 'call', 'we', 'need', 'type', 'interday', 'analysis', '.']\n",
            "delainey-d\n",
            "\t['brian.redmond', '@', 'enron.com', ',', 'max.yzaguirre', '@', 'enron.com', ',', 'rob.milnthorp', '@', 'enron.com', 'Guys', ',', 'details', 'the', 'ESA', 'MEH', 'turbines', '-', 'please', 'forward', 'project', 'details', ',', 'economics', 'strategy', 'ASAP', '.', 'We', 'allocate', 'turbines', 'the', 'project', 'the', 'best', 'strategic/economic', 'rationale', 'confirming', 'they', 'are', 'worth', 'in', 'ENA', 'versus', 'ESA', '.', 'If', 'need', 'detailed', 'information', 'these', 'turbines', 'please', 'let', 'know', '.', 'Rob', ',', 'please', 'give', 'call', 'this', 'one', '.', 'TIME', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', 'Brett', 'R', 'Wiggs', '@', 'ENRON', 'DATE', 'TIME', 'The', 'attached', 'sheet', 'provides', 'summary', 'information', 'the', 'turbines', '.', 'David', 'W', 'Delainey', '@', 'ECT', 'DATE', 'TIME', 'Brett', ',', 'you', 'give', 'me', 'the', 'particulars', 'the', 'four', 'MEH', 'turbines', '(', 'ie', ')', 'scheduled', 'delivery', ',', 'price', ',', 'fuel', 'options', ',', 'heat', 'rate', ',', 'output', ',', 'etc', '-', 'including', 'transferablility', 'NA', '.']\n",
            "\t['christopher.calger', '@', 'enron.com', ',', 'wes.colwell', '@', 'enron.com', ',', 'janet.dietrich', '@', 'enron.com', ',', 'jeff.donahue', '@', 'enron.com', ',', 'w.duran', '@', 'enron.com', ',', 'mark.haedicke', '@', 'enron.com', ',', 'gary.hickerson', '@', 'enron.com', ',', 'mike.jakubik', '@', 'enron.com', ',', 'scott.josey', '@', 'enron.com', ',', 'john.lavorato', '@', 'enron.com', ',', 'rodney.malcolm', '@', 'enron.com', ',', 'george.mcclellan', '@', 'enron.com', ',', 'rob.milnthorp', '@', 'enron.com', ',', 'julia.murray', '@', 'enron.com', ',', 'jere.overdyke', '@', 'enron.com', ',', 'david.oxley', '@', 'enron.com', ',', 'kevin.presto', '@', 'enron.com', ',', 'brian.redmond', '@', 'enron.com', ',', 'jeffrey.shankman', '@', 'enron.com', ',', 'c.thompson', '@', 'enron.com', ',', 'max.yzaguirre', '@', 'enron.com', ',', 'james.ajello', '@', 'enron.com', ',', 'edward.ondarza', '@', 'enron.com', ',', 'vince.kaminski', '@', 'enron.com', ',', 'beth.perlman', '@', 'enron.com', ',', 'david.delainey', '@', 'enron.com', 'dan.leff', '@', 'enron.com', ',', 'mark.frevert', '@', 'enron.com', ',', 'patti.thompson', '@', 'enron.com', ',', 'catherine.dumont', '@', 'enron.com', ',', 'marsha.schiller', '@', 'enron.com', ',', 'mollie.gustafson', '@', 'enron.com', ',', 'shirley.tijerina', '@', 'enron.com', ',', 'christy.chapman', '@', 'enron.com', ',', 'tina.rode', '@', 'enron.com', ',', 'janette.elbertson', '@', 'enron.com', ',', 'stella.ely', '@', 'enron.com', ',', 'nicole.mayer', '@', 'enron.com', ',', 'tonai.lehr', '@', 'enron.com', ',', 'kimberly.hillis', '@', 'enron.com', ',', 'ana.alcantara', '@', 'enron.com', ',', 'yolanda.ford', '@', 'enron.com', ',', 'carolyn.george', '@', 'enron.com', ',', 'donna.baker', '@', 'enron.com', ',', 'rhonna.palmer', '@', 'enron.com', ',', 'felicia.doan', '@', 'enron.com', ',', 'katherine.benedict', '@', 'enron.com', ',', 'barbara.lewis', '@', 'enron.com', ',', 'pilar.cerezo', '@', 'enron.com', ',', 'terrellyn.parker', '@', 'enron.com', ',', 'dusty.paez', '@', 'enron.com', ',', 'shirley.crenshaw', '@', 'enron.com', ',', 'nicki.daw', '@', 'enron.com', ',', 'cherylene.westbrook', '@', 'enron.com', ',', 'kay.chapman', '@', 'enron.com', ',', 'cindy.skinner', '@', 'enron.com', ',', 'carol.moffett', '@', 'enron.com', ',', 'stacy.oravec', '@', 'enron.com', 'dan.leff', '@', 'enron.com', ',', 'mark.frevert', '@', 'enron.com', ',', 'patti.thompson', '@', 'enron.com', ',', 'catherine.dumont', '@', 'enron.com', ',', 'marsha.schiller', '@', 'enron.com', ',', 'mollie.gustafson', '@', 'enron.com', ',', 'shirley.tijerina', '@', 'enron.com', ',', 'christy.chapman', '@', 'enron.com', ',', 'tina.rode', '@', 'enron.com', ',', 'janette.elbertson', '@', 'enron.com', ',', 'stella.ely', '@', 'enron.com', ',', 'nicole.mayer', '@', 'enron.com', ',', 'tonai.lehr', '@', 'enron.com', ',', 'kimberly.hillis', '@', 'enron.com', ',', 'ana.alcantara', '@', 'enron.com', ',', 'yolanda.ford', '@', 'enron.com', ',', 'carolyn.george', '@', 'enron.com', ',', 'donna.baker', '@', 'enron.com', ',', 'rhonna.palmer', '@', 'enron.com', ',', 'felicia.doan', '@', 'enron.com', ',', 'katherine.benedict', '@', 'enron.com', ',', 'barbara.lewis', '@', 'enron.com', ',', 'pilar.cerezo', '@', 'enron.com', ',', 'terrellyn.parker', '@', 'enron.com', ',', 'dusty.paez', '@', 'enron.com', ',', 'shirley.crenshaw', '@', 'enron.com', ',', 'nicki.daw', '@', 'enron.com', ',', 'cherylene.westbrook', '@', 'enron.com', ',', 'kay.chapman', '@', 'enron.com', ',', 'cindy.skinner', '@', 'enron.com', ',', 'carol.moffett', '@', 'enron.com', ',', 'stacy.oravec', '@', 'enron.com', 'As', 'move', 'Spring/Summer', '2000', ',', 'time', 'turn', 'attention=', '=20', 'performance', 'review', 'process', '.', 'Mid-year', 'always', 'busy', 'we', 'a=', '=20', 'number', 'important', 'tasks', 'projects', 'process', '.', 'While', 'recognizing', ',', '=', '=20', 'remains', 'extremely', 'important', 'take', 'time', 'next', 'weeks', 'gath=', 'er=20', 'necessary', 'information', 'provide', 'quality', 'meaningful', 'feedback', 'our=20', 'employees', ',', 'well', 'utilize', 'information', 'year', 'end', 'review=', '=20', 'process', '.', 'In', 'spirit', 'One', 'Enron', ',', 'Performance', 'Review', 'Process', '(', 'PRC', ')', 'be=20', 'global', 'Mid-year', '2000', '.', 'Vice', 'Presidents', 'above', 'across', 'operating=', '=20', 'companies', 'reviewed', 'discussed', 'consistent', 'manner', 'with=20', 'identical', 'criteria', '.', 'ENA', 'review', 'professional', 'level', 'above=20', 'employees', '.', 'The', 'timeline', 'training', 'midyear', 'process', 'outlined', '=', 'at=20', 'end', 'memo', '.', 'Your', 'HR', 'Business', 'Consultant', 'also', 'available', 'to=20', 'answer', 'questions', '.', 'With', 'regards', 'Global', 'Functions', ',', 'review', 'sessions', 'led', 'the=20', 'Global', 'and/or', 'Corporate', 'Functional', 'heads', ',', 'designed', 'calibrate=', '=20', 'personnel', 'within', 'areas', 'expertise', '.', 'The', 'Global', 'Functional', 'Review=20', 'Areas', 'include', ':', '_', 'NetWorks/Technology', '_', 'Human', 'Resources', '_', 'Public', 'Relations', '&', 'Reg', 'Affairs=09G', '.', 'Whalley', '=09R', '.', 'Causey', '=09R', '.', 'Buy', '=09A', '.', 'Fastow', '=09C', '.', 'Olson', '=09S', '.', 'Kean', '=20', 'ENA', 'Mid-Year', 'Process', ':', 'ENA', 'received', 'favorable', 'feedback', 'review', 'process', 'used', 'Mid-year=', '=20', 'Year-end', '1999', ',', ',', 'follow', 'same', 'general', 'guidelines', 'and=', '=20', 'process', 'Mid-year', '2000', '.', 'The', 'following', 'key', 'features', 'Mid-year=', '=20', '2000', 'process', ':', 'The', 'focus', 'feedback', 'continue', 'be', 'the', 'qualitative', 'aspects', ',', '=', '=20', 'opposed', 'quantitative', '.', 'Toward', 'end', ',', 'communication', 'the', 'employee=', '=01', ',', 's=20', 'explicit', 'ranking', 'be', 'left', 'the', 'discretion', 'the', 'business', 'unit', 'manage=', 'r.', 'Initial', 'discussions', 'employees', 'regarding', 'accomplishments', ',', 'are=', '=20', 'highly', 'encouraged', ',', 'prior', 'the', 'Business', 'Review', 'Meetings', '.', 'Mid-year', 'performance', 'results', 'be', 'used', 'baseline', 'performance=20', 'information', 'Year-end', '2000.', 'Creation', '3', 'standard', 'feedback', 'forms', 'all', 'peer', 'groups', '.', '=20', 'Standardization', 'criteria', 'all', 'peer', 'groups', '.', 'Utilization', 'consistent', '6', 'gradation', 'rating', 'scale', '.', '=20', 'All', 'exempt', 'employees', 'be', 'discussed', 'Business', 'Review', 'Meetings', 'and=20', 'placed', 'one', 'six', 'categories', 'peer', 'group', '.', 'ENA', 'VP', \"'s\", 'be', 'pre-rank=', 'ed=20', 'the', 'ENA', 'Office', 'the', 'Chairman', 'Managing', 'Directors', 'prior', 'the', 'Enron=', '=20', 'PRC', '.', 'Non-exempt', '(', 'overtime', 'eligible', ')', 'employees', 'be', 'evaluated', 'their=', '=20', 'supervisors', 'placed', 'one', 'the', '6', 'categories', '.', 'The', 'results', 'the=20', 'Business', 'Review', 'Meetings', 'be', 'the', 'final', 'rankings', 'exempt', 'employees=20', 'VP', ',', 'subject', 'ENA', 'Office', 'the', 'Chairman', '.', 'A', 'minimum', 'two', 'representatives', 'functional', 'areas', 'be=20', 'required', 'the', 'Business', 'Review', 'Meetings', '.', 'The', 'meetings', 'otherwise', 'be=', '=20', 'rescheduled', 'allow', 'this', 'very', 'important', 'representation', 'take', 'place', '.', 'The=', '=20', 'nominated', 'individuals', 'illustrated', '.', 'The', 'top', '5', 'HR', 'priorities/challenges', '2000', 'also', 'be', 'agreed', 't=', 'he=20', 'Business', 'Review', 'Meetings', '.', 'Analysts', 'Associates', 'will', 'be', 'pre-reviewed', 'a', 'Business', 'Review', 'Meeting=', 's=20', 'based', 'their', 'current', 'rotation', ',', 'cross-calibrated', 'the', 'Enron', 'Global=', '=20', 'Analyst', 'Associate', 'Business', 'Review', 'Meeting', '.', 'Peer', 'Groups', ':', 'Commercial', 'Support', 'Specialized', 'Technical', 'Performance', 'Criteria', '(', 'all', 'peer', 'groups', ')', ':', 'Innovation/Entrepreneurship', 'Communication/Setting', 'Direction', 'Teamwork/Interpersonal', 'Leadership/Vision/Values=20', 'Analytical/Technical', 'Use', 'multiple', 'sources', 'input', 'encouraged', '(', 'employee', ',', 'peers', ',', 'direct=', '=20', 'reports', ',', 'internal', 'customers', ',', 'external', 'customers', ')', ',', 'is', 'a', 'self-evaluation', 'Employees', 'recommend', '5-10', 'reviewers', 'Supervisor', 'Supervisor=20', 'select', 'least', 'three', 'the', 'employee=01', ',', 'recommendations', 'All', 'feedback', 'must', 'be', 'entered', 'via', 'the', 'Performance', 'Management', 'System', 'locate=', 'd=20', 'the', 'intranet', 'Supervisor', 'consolidate', 'the', 'feedback', ',', 'prepare', 'a', 'draft', 'the=20', 'Performance', 'Review', 'form', 'meet', 'the', 'employee', 'prior', 'the', 'Business=20', 'Final', 'feedback', 'exempt', 'employee', 'follows', 'the', 'July', '28th', 'meeting', 'For', 'VP', \"'s\", '&', 'MD', \"'s\", ',', 'final', 'feedback', 'follows', 'the', 'Enron', 'Executive', 'Committee=20', 'Business', 'Review', 'Meetings', '/', 'VP', 'Pre-Ranking', 'Committee', 'Meeting=20', 'Responsibilities', '/', 'Actions', ':', 'The', 'following', 'list', 'represents', 'suggested', 'groups', 'the', 'individuals=20', 'responsible', 'each', 'Business', 'Review', 'Meeting', '.', 'Attendees', 'at', 'the', 'meetings', 'ar=', 'e=20', 'appropriate', 'Supervisors', 'within', 'the', 'Business', 'Unit', '.', 'In', 'addition', ',', 'the', 'Office', '=', 'of=20', 'the', 'Chairman', 'requires', 'the', 'attendance', 'two', 'three', 'other', 'senior', 'level=20', 'representatives', 'other', 'Business', 'Units', 'add', 'external', 'perspective', '.', 'Area/Function=09ENA', 'Lead=09Global/Functional', 'Lead', '*', '=09Required', 'Non-functiona=', 'l', 'Attendees', '=09=09=09', 'COMMERCIAL=09=09=09', '=09=09=09', 'Trading=09Presto=09=09Dietrich', '=09Shankman=09=09Calger', '=09Lavorato=09=09Bowen', '=09McClellan=09=09Ajello', '=09Hickerson=09=09Delainey', '=09Belden=09=09', '=09=09=09', 'Origination=09Redmond=09=09Shankman', '=09Dietrich=09=09McClellan', '=09Milnthorp=09=09Belden', '=09Calger=09=09Presto', '=09Donahue=09=09Delainey', '=09Bowen=09=09Lavorato', '=09Ajello=09=09', '=09Duran=09=09', '=09Ondarza=09=09', '=09Malcolm=09=09', '=09Overdyke=09=09', '=09Thompson/Josey=09=09', '=09Yzaguirre=09=09', '=09=09=09', 'Finance', '(', '*', ')', '=09Jakubik=09Fastow=09', '=09=09=09', 'COMMERCIAL', 'SUPPORT=09=09=09', 'TECHNICAL', '=09=09=09', 'SPECIALIZED', 'TECHNICAL=09=09=09', '=09=09=09', 'Legal=09Haedicke=09=09', 'Research=09Kaminski=09=09', 'RAC=09Buy=09=09', 'Technical=09Miller/Parquet=09=09', '=09=09=09', 'Energy', 'Operations', '(', '*', ')', '=09Beck=09Causey=09Colwell', '=09=09=09Oxley', '=09=09=09', 'Business', 'Analysis', '&', 'Reporting/Tax', '(', '*', ')', '=09Colwell=09Causey=09Beck', '=09Mintz=09=09', '=09=09=09', 'Human', 'Resources', '(', '*', ')', '=09Oxley=09Olson=09', '=09=09=09', 'Public', 'Relations', '(', '*', ')', '=09Palmer=09Kean=09', '=09=09=09', 'NetWorks/Technology', '(', '*', ')', '=09Perlman=09Whalley/McConnell=09', '(', '*', ')', 'Note', ':', 'Global', 'Functional', 'Review', 'meetings', 'be', 'held', 'these', 'areas', '.', 'ENA', 'VP', 'Pre-Ranking', 'Committee', ':', 'Ray', 'Bowen=09Mark', 'Frevert=09Dan', 'Leff', '(', 'non', 'ENA', 'rep', ')', '=09David', 'Oxley', 'Dave', 'Delainey=09Brian', 'Redmond=09George', 'McClellan=09Mark', 'Haedicke', 'Janet', 'Dietrich=09Julia', 'Murray=09Jeff', 'Shankman=09Gary', 'Hickerson', 'Jeff', 'Donahue=09Jere', 'Overdyke=09Marty', 'Sunde', '(', 'non', 'ENA', 'rep', ')', '=09John', 'Lavorato', 'Outcomes', 'Business', 'Review', 'Meetings/', 'VP', 'Pre-Ranking', 'Committee', 'Meetings', ':', 'Calibration', 'employees', 'six', 'gradations=20', 'Promotion', 'nominations', 'VP', 'Assessment', 'the', '=01', '&', 'right', 'people', 'the', 'right', 'jobs=018', 'Assessment', 'gaps', 'what', 'is', 'needed', 'the', 'Business', 'Unit', '(', 'skills', ',', '=20', 'capabilities', ',', 'training', ',', 'experience', ')', 'Top', 'five', 'HR', 'challenges', 'Feedback', 'employees', 'the', 'results', 'the', 'meetings', ',', 'as', 'applicable', 'PEP', 'System', 'Open', 'Feedback', 'May', '17=20', 'PEP', 'System', 'Closes', 'Feedback', 'June', '9=20', 'Feedback', 'Collection/Initial', 'Employee', 'May', '17-June', '12', 'Discussions', '=20', 'Global', 'Functional', 'Review', 'Meetings', 'June', '12-June', '16', 'ENA', 'Business', 'Review', 'Meetings', 'June', '12-July', '25', 'ENA', 'VP', 'Pre-Ranking', 'Committee', 'Meeting', 'July', '28', 'Enron', 'Executive', 'Committee', 'meeting', 'July', '31-Aug.', '1']\n",
            "fossum-d\n",
            "\t['Dammit', 'Jenkins', ',', \"n't\", 'even', 'joke', 'stuff', 'like', '!', 'If', 'market', 'ever', 'realized', 'I', 'worked', ',', 'stock', 'would', 'go', '$', '10', '!', '!', '!', 'You', 'think', 'Lay', 'taking', 'first', 'step', 'toward', 'Sec', '.', 'Treas', '.', 'new', 'Bush', 'admin', '?', '?', '?', 'That', \"'s\", 'rumor', 'I', 'heard', 'month', 'ago', '.', 'Hope', 'goes', 'well', 'sunny', 'hotlanta', '.', 'Its', '5', 'zero', 'today', 'your', 'whole', 'Georgia', 'good', 'ole', \"'\", 'boy', 'lifestyle', 'thing', 'sounds', 'pretty', 'attractive', '.', 'AMF', 'DF', \"''\", 'Alan', 'Jenkins', \"''\", '<', 'ajenkins', '@', 'lanlaw.com', '>', 'DATE', 'TIME', 'I', 'trust', 'you', 'guys', 'saw', 'wires', 'today', ':', 'Enron', \"'s\", 'stock', 'off', '$', '3-3/16', '4.1', 'percent', 'afternoon', 'trading', '$', '74', ',', 'following', 'announcement', 'Jeff', 'Skilling', 'become', 'new', 'chief', 'executive', 'officer', 'Feb.', '12', '.', 'An', 'analyst', ',', 'asked', 'to', 'named', ',', 'said', 'it', 'been', 'widely', 'assumed', 'Drew', 'Fossum', 'would', 'named', 'CEO', ';', 'therefore', ',', 'the', 'company', \"'s\", 'stock', 'traded', 'lower', 'on', 'the', 'news', '.']\n",
            "\t['Thanks', '--', 'I', \"'ll\", 'pass', 'info', 'employment', 'guys', '.', 'df', 'A', 'friend', 'friend', '(', 'Petula', 'Workman', ')', 'looking', 'part', 'time', 'legal', 'position', '.', 'She', 'a', 'great', 'lawyer', '--', 'on', 'law', 'review', ',', 'people', 'worked', 'love', ',', 'wants', 'a', 'part', 'time', 'gig', 'since', 'she', 'is', 'a', 'mom', 'kid', 'responsibilities', '.', 'She', 'wants', 'to', 'work', 'part-time', '(', '20-24', 'hours/week', ')', 'preferably', 'employment', 'litigation', ',', 'commercial', 'litigation', 'would', 'work', '.', 'If', 'have', 'need', 'know', 'someone', 'does', ',', 'let', 'know', 'I', \"'ll\", 'get', 'her', 'resume', 'you', '.']\n",
            "arnold-j\n",
            "\t['saw', 'lot', 'bulls', 'sell', 'summer', 'length', 'front', 'mitigate', 'margins/absolute', 'position', 'limits/var', '.', 'guys', 'taking', 'front', ',', 'also', 'buying', 'back', 'summer', '.', 'el', 'paso', 'large', 'buyer', 'next', 'winter', 'today', 'taking', 'spreads', '.', 'certainly', 'reason', 'spreads', 'so', 'strong', 'way', 'piece', '.', 'really', 'the', 'only', 'one', 'left', 'any', 'risk', 'premium', 'built', 'h/j', '.', 'trading', 'equivalent', '180', 'access', ',', '40+', 'this', 'morning', '.', 'certainly', 'are', 'entering', 'period', 'bearish', 'neutral', 'trade', ',', 'h/j', 'get', 'whacked', '.', 'certainly', 'understand', 'the', 'arguments', 'h/j', '.', 'h', 'settles', '$', '20', ',', 'spread', 'is', 'probably', 'worth', '$', '10', '.', 'H', '20', 'call', 'was', 'trading', '55', 'monday', '.', 'today', 'was', '10/17', '.', 'the', 'market', \"'s\", 'view', 'probability', 'h', 'going', 'crazy', 'certainly', 'changed', 'past', '48', 'hours', 'and', 'that', 'reflected', 'h/j', '.', 'slafontaine', '@', 'globalp.com', 'DATE', 'TIME', 'mkt', 'getting', 'a', 'little', 'bearish', 'the', 'back', 'winter', 'think-if', 'we', 'get', 'another', 'cold', 'blast', 'jan/feb', 'mite', 'move', '.', 'oil', 'moving', 'and', 'march', 'closer', 'flat', 'wide', 'to', 'jan', 'im', 'so', 'bearish', 'these', 'sprds', 'now-less', 'bullish', 'march', 'april', 'well', '.']\n",
            "\t['Just', 'update', ':', 'Today', 'I', 'set', 'front', 'month', 'fixed', 'price', 'gas', 'daily', 'product', 'priced', 'parity', 'NYMEX', '.', 'I', 'thought', 'response', 'tremendous', '.', 'It', 'really', 'shows', 'we', 'might', 'an', 'angle', 'put', 'more', 'curve', 'become', 'predominant', 'benchmark', 'the', 'industry', 'rather', 'the', 'exchange', '.', 'One', 'problem', 'I', 'was', 'linking', '2', 'syncopated', 'basis', 'products', '.', 'I', 'set', 'a', 'new', 'product', 'the', 'prompt', 'was', 'Nov', 'GD/D', 'Henry', 'Hub', 'was', 'a', 'syncopated', 'basis', '0/0', 'the', 'Nov', 'Nymex', '.', 'However', ',', 'since', 'Dec', 'Nymex', 'a', 'syncopated', 'basis', 'Nov', 'Nymex', ',', 'I', 'could', 'set', 'a', 'syncopated', 'basis', 'link', 'around', 'the', 'Dec', 'Nymex', '.', 'Any', 'ideas', '?']\n",
            "beck-s\n",
            "\t['Thanks', 'rounding', 'tickets', 'Orange', 'Bowl', '.', 'You', 'mail', ',', 'hold', 'until', 'I', 'see', 'Christmas', '.', 'Mike', \"'s\", 'wife', 'decided', 'make', 'trip', ',', 'wo', \"n't\", 'using', 'tickets', '.', 'Jody', 'Crook', 'use', 'other', 'two', 'tickets', '.', 'Lunch', 'week', 'Christmas', 'New', 'Years', 'sounds', 'great', '.', 'I', 'working', 'week', ',', 'would', 'be', 'glad', 'meet', 'guys', 'Champions', 'lunch', 'best', '.', 'Or', 'game', 'Irma', \"'s\", ',', 'just', 'let', 'know', 'would', 'like', 'come', 'downtown', '.', '--', 'Sally', \"''\", 'Jacobs', ',', 'Ted', 'K', \"''\", '<', 'tjacobs', '@', 'ou.edu', '>', 'DATE', 'TIME', '<', 'mmcconn2', '@', 'ect.enron.com', '>', 'Sally/Mike', ',', 'I', 'be', 'Houston', 'week', 'after', 'Christmas', '(', '12/26-12/29', ')', 'was', 'wondering', 'the', 'two', 'going', 'be', 'the', 'office', ',', ',', 'would', 'you', 'be', 'available', 'lunch', '?', 'In', 'talking', 'David', 'Beck', ',', 'he', 'was', 'going', 'try', 'arrange', 'golf', 'game', '(', 'Mike', ',', ',', 'Richard', 'Kimberlin', 'David', ')', 'one', 'those', 'afternoons', 'Champions', '.', 'If', 'that', 'is', 'possible', ',', 'maybe', 'lunch', 'golf', 'might', 'work', '.', 'If', ',', 'I', 'meet', 'you', 'downtown', 'convenient', '.', 'Let', 'know', 'your', 'schedules', 'like', 'I', 'plan', 'schedule', 'accordingly', '.', 'Also', ',', 'I', 'need', 'know', 'I', 'need', 'mail', 'the', 'Orange', 'Bowl', 'tickets', 'both', 'you', 'separately', 'just', 'one', 'you', '.', 'Did', \"n't\", 'know', 'you', 'planning', 'going', 'Miami', 'together', '?', 'I', 'receive', 'the', 'tickets', 'the', 'next', 'day', 'two', 'will', 'whatever', '.', 'Ought', 'be', 'fun', 'trip', ',', 'it', 'definitely', 'awhile', 'since', 'the', 'Sooners', 'been', 'to', 'Miami', '.', 'Anyway', ',', 'let', 'me', 'know', 'if', 'you', 'available', 'lunch/gold', 'just', 'lunch', '.', 'Hope', 'you', 'all', 'a', 'wonderful', 'holiday', 'season', 'most', 'all', 'get', 'to', 'spend', 'time', 'your', 'families', '!', 'Ted', 'K.', 'Jacobs', 'Director', 'Energy', 'Management', 'The', 'University', 'Oklahoma', '307', 'West', 'Brooks', ',', 'Room', '218', 'Norman', ',', 'OK', '73019-4007', '(', '405', ')', '325-0758', '(', '405', ')', '325-2096', 'fax', '-', 'C.DTF']\n",
            "\t['The', 'week', 'November', '13', 'week', 'Enron', 'Management', 'Conference', 'San', 'Antonio', '.', 'It', 'begins', 'Wednesday', 'evening', ',', 'most', 'people', 'travelling', 'Wednesday', 'afternoon', '.', 'I', 'office', 'Monday', 'Tuesday', 'week', ',', 'those', 'days', 'work', 'well', 'your', 'visit', '.', 'I', 'wanted', 'know', 'conference', 'case', 'impact', 'other', 'meetings', 'might', 'want', 'Houston', 'week', '.', 'Let', 'know', '.', 'I', 'look', 'forward', 'seeing', 'introducing', 'others', 'the', 'team', '.', 'We', 'looking', 'forward', 'seeing', 'Mo', 'next', 'week', 'Houston', '.', 'Have', 'great', 'weekend', '.', '--', 'Sally', 'DATE', 'TIME', 'Hi', '--', '-', 'Had', 'lunch', 'Mo', 'today', '--', 'can', 'imagine', 'interested', 'my', 'new', 'role', ',', 'working', '.', 'Fernley', 'decided', 'too', 'hard', 'write', 'the', 'organizational', 'changes', 'how', 'affects', 'all', 'the', 'people', 'reported', 'Phillip', 'I', ',', 'he', 'has', 'verbally', 'announced', 'the', 'changes', '.', 'But', ',', 'any', 'rate', ',', 'the', 'word', 'getting', '.', 'I', \"n't\", 'seen', 'Mo', 'months', ',', 'it', 'was', 'good', 'catch', '.', 'I', 'think', 'headed', 'Houston', 'week', '(', 'is', 'Frank', ')', 'I', 'sure', 'you', 'be', 'hearing', 'her', '.', 'I', 'have', 'tentatively', 'blocked', 'the', 'week', 'beginning', 'Monday', ',', 'Nov.', '13th', 'come', 'Houston', ',', 'would', 'like', 'to', 'spend', 'of', 'time', 'you', 'your', 'team', ',', 'meeting', 'people', ',', 'maybe', 'just', 'following', 'you', 'around', 'the', 'day', ',', 'as', 'you', 'suggested', '.', 'Does', 'week', 'work', 'you', '?', 'I', 'think', 'the', 'Management', 'conference', 'is', 'later', 'in', 'the', 'month', ',', 'people', 'generally', 'be', 'around', '.', 'Please', 'let', 'me', 'know', ',', 'I', 'make', 'sure', 'it', 'happens', '.', 'I', 'will', 'also', 'need', 'to', 'spend', 'time', 'Melissa', 'Becker', 'and', 'her', 'team', 'working', 'Post', 'ASE', 'Reporting', 'solutions', ',', 'will', 'plan', 'to', 'spend', 'significant', 'amount', 'of', 'time', 'the', 'North', 'America', 'group', '.', 'What', 'you', 'think', '?', 'I', 'ready', 'to', 'get', 'moving', 'some', 'new', 'things', '!', '!', '!', '!']\n",
            "campbell-l\n",
            "\t['The', 'third', 'quarter', 'PCB', 'meeting', 'Southern', 'California', 'Gas', 'Company', 'held', 'morning', '.', 'SoCal', 'presented', 'third', 'quarter', 'invoce', 'their', 'PCB', 'management', 'disposal', 'activities', 'Transwestern', 'responsible', '$', '120,602.19', '.', 'All', 'charges', 'appropriate', 'considered', 'normal', 'operating', 'expenses', 'PCB', 'activities', 'California', '.', 'The', 'public', 'hearing', 'held', 'Williams', ',', 'AZ', 'Kingman', 'Flagstaff', 'air', 'permits', 'Redrok', 'Expansion', '.', 'There', 'no', 'comments', 'concerns', 'brought', 'at', 'meeting', 'no', 'individuals', 'came', 'meeting', '.', 'An', 'email', 'received', 'ADEQ', 'presenting', 'minor', 'additions', 'added', 'each', 'permit', '.', 'Each', 'comment', 'addition', 'not', 'impact', 'change', 'the', 'draft', 'permits', 'which', 'received', 'earlier', 'month', '.', 'The', 'permits', 'Klagetoh', 'Luepp', 'were', 'received', 'the', 'EPA', 'last', 'week', '.', 'The', 'permits', 'the', 'ADEQ', 'the', 'Kingman', 'Flagstaff', 'C/S', 'will', 'be', 'issued', 'the', 'later', 'part', 'this', 'week', '.', 'Attended', 'the', 'incident', 'investigation', 'technical', 'writing', 'workshop', 'Omaha', '.', 'Assisted', 'the', 'Mountainair', 'team', 'the', 'semiannual', 'Title', 'V', 'compliance', 'monitoring', 'report', 'C/S', 'No.7', '.', 'A', 'meeting', 'held', 'Phoenix', ',', 'Az', 'PG', '&', 'E', 'review', 'charges', 'invoices', 'PG', '&', 'E', 'PCB', 'management', 'disposal', 'activities', 'their', 'system', 'the', 'last', 'several', 'months', '.', 'Also', 'discussed', 'recent', 'liquids', 'sampling', 'results', 'proposed', 'PCB', 'activities', 'the', 'PG', '&', 'E', 'system', '2002', '.']\n",
            "\t['http', ':', '//quotes.freerealtime.com/rt/frt/news', '?', 'symbol=PMCS', '&', 'art=C2000090100245b1087']\n",
            "badeer-r\n",
            "\t['mitch.mcclintock', '@', 'enron.com', 'I', 'be', 'of', 'office', 'Friday', ',', 'Monday', 'Tuesday', 'vacation', '.', 'I', 'be', 'able', 'be', 'reached', 'cell', 'phone', 'necessary', '.']\n",
            "\t['is', 'fax', 'number', '?']\n",
            "brawner-s\n",
            "\t['``', 'Jon', 'Schnitzer', \"''\", '<', 'jons', '@', 'amerexenergy.com', '>', 'DATE', 'TIME', '>', '>', '>', '>', '>', 'A', 'priest', 'took', 'sebatacle', 'fishing', 'lodge', '.', 'On', 'last', 'day', '>', '>', '>', '>', 'trip', 'hooked', 'monster', 'fish', 'proceeded', 'reel', '.', 'The', '>', '>', '>', '>', 'holding', 'net', ',', 'yelled', '``', 'Look', 'size', 'Son', 'Bitch', '!', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', 'Son', ',', 'I', \"'m\", 'priest', '.', 'Your', 'language', 'uncalled', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'No', ',', 'Father', ',', \"'s\", 'kind', 'fish', '.', 'A', 'Son', 'Bitch', 'fish', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Really', '?', 'Well', 'help', 'land', 'Son', 'Bitch', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Once', 'boat', ',', 'marveled', 'monster', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Father', ',', 'is', 'biggest', 'Son', 'Bitch', 'I', \"'ve\", 'ever', 'seen', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Yes', ',', 'Son', ',', 'is', 'big', 'Son', 'Bitch', '.', 'What', 'I', '?', '>', '>', '>', '>', '>', '>', '>', '>', 'Why', 'eat', 'course', '.', 'You', \"'ve\", 'never', 'tasted', 'anything', 'good', '>', '>', 'Son', '>', '>', '>', '>', 'a', 'Bitch', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Elated', ',', 'priest', 'headed', 'home', 'church', '.', 'While', 'unloading', '>', '>', 'gear', ',', '>', '>', '>', '>', 'prize', 'catch', ',', 'Sister', 'Mary', 'inquired', 'his', 'trip', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Take', 'a', 'look', 'big', 'Son', 'a', 'Bitch', 'I', 'caught', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Sister', 'Mary', 'gasped', 'clutchted', 'rosary', ',', '``', 'Father', '!', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', 'It', \"'s\", 'ok', 'Sister', '.', 'That', \"'s\", 'kind', 'fish', 'is', '.', 'A', 'Son', 'a', 'Bitch', '>', '>', 'fish', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'Oh', ',', 'well', 'what', 'going', 'do', 'that', 'big', 'Son', 'a', 'Bitch', '?', '>', '>', '>', '>', '>', '>', '>', '>', 'Why', ',', 'eat', 'course', '.', 'The', 'guide', 'said', 'nothing', 'compares', 'taste', '>', '>', '>', '>', '>', 'a', '>', '>', '>', '>', 'Son', 'a', 'Bitch', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Sister', 'informed', 'priest', 'that', 'Pope', 'scheduled', 'visit', '>', '>', '>', '>', '>', 'a', '>', '>', '>', '>', 'days', 'that', 'should', 'fix', 'Son', 'a', 'Bitch', 'dinner', '.', '>', '>', \"''\", \"I'll\", '>', '>', '>', '>', 'even', 'clean', 'Son', 'a', 'Bitch', \"''\", ',', 'said', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'As', 'cleaning', 'huge', 'fish', ',', 'Friar', 'walked', '.', 'What', '>', '>', '>', '>', 'Sister', '?', '>', '>', '>', '>', '>', '>', '>', '>', 'Father', 'wants', 'clean', 'big', 'Son', 'a', 'Bitch', \"Pope's\", '>', '>', 'dinner', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Sister', '!', 'I', \"'ll\", 'clean', 'if', \"'re\", 'upset', '!', 'Please', 'watch', 'language', '!', '>', '>', '>', '>', '>', '>', '>', '>', 'No', ',', ',', '.', 'It', \"'s\", 'called', 'a', 'Son', 'a', 'Bitch', 'fish', '.', 'Really', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'Oh', ',', 'well', 'that', 'case', 'I', \"'ll\", 'fix', 'a', 'great', 'meal', 'that', 'Son', 'a', '>', '>', 'Bitch', '>', '>', '>', '>', 'be', 'main', 'course', '!', 'Let', 'know', \"'ve\", 'finished', 'cleaning', '>', '>', 'that', '>', '>', '>', '>', 'Son', 'a', 'Bitch', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'On', 'night', 'the', 'Pope', \"'s\", 'visit', ',', 'everything', 'perfect', '.', 'The', 'Friar', '>', '>', '>', '>', '>', '>', 'prepared', 'excellent', 'meal', ',', 'was', 'wine', ',', 'the', 'fish', 'was', '>', '>', 'excellent', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Pope', 'said', ',', '``', 'This', 'is', 'great', 'fish', ',', 'did', 'you', 'get', '?', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', '``', 'I', 'caught', 'the', 'Son', 'a', 'Bitch', '!', \"''\", 'proclaimed', 'the', 'proud', 'priest', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Pope', \"'s\", 'eyes', 'opened', 'wide', ',', 'he', 'said', 'nothing', '.', '>', '>', '>', '>', '>', '>', '>', '>', '``', 'And', 'I', 'cleaned', 'the', 'Son', 'a', 'Bitch', '!', \"''\", 'exclaimed', 'the', 'sister', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Pope', 'sat', 'silent', 'disbelief', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'And', 'the', 'friar', 'added', ',', '``', 'And', 'I', 'prepared', 'the', 'Son', 'a', 'Bitch', ',', 'using', 'a', '>', '>', '>', 'special', '>', '>', '>', '>', 'recipe', '!', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', 'The', 'Pope', 'looked', 'each', 'them', '.', 'Slowly', 'a', 'big', 'smile', 'creeped', 'across', '>', '>', 'his', '>', '>', '>', '>', 'face', '.', '>', '>', '>', '>', '>', '>', '>', '>', 'You', 'fuckers', 'alright', '!', '!', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', '>', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '>', '>', 'This', 'email', 'any', 'files', 'transmitted', 'with', 'it', 'the', 'ElPaso', '>', '>', 'Corporation', 'confidential', 'intended', 'solely', 'the', '>', '>', 'use', 'of', 'the', 'individual', 'entity', 'to', 'whom', 'are', 'addressed', '.', '>', '>', 'If', 'you', 'have', 'received', 'this', 'email', 'in', 'error', 'please', 'notify', 'the', '>', '>', 'sender', '.', '>', '>', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '>', '>', '_________________________________________________________________', '>', 'Get', 'FREE', 'download', 'of', 'MSN', 'Explorer', 'http', ':', '//explorer.msn.com']\n",
            "\t['TIME', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', \"''\", 'susan', 'schnitzer', \"''\", '<', 's.schnitzer', '@', 'worldnet.att.net', '>', 'DATE', 'TIME', '--', '--', '-Original', 'Message', '--', '--', '-', '<', 'hanaone', '@', 'aol.com', '>', ';', 'bbron58584', '@', 'aol.com', '<', 'bbron58584', '@', 'aol.com', '>', ';', 'lcbron', '@', 'aol.com', '<', 'lcbron', '@', 'aol.com', '>', ';', 'giannini_sa', '@', 'williscorroon.com', '<', 'giannini_sa', '@', 'williscorroon.com', '>', ';', 'danielle.karwoski', '@', 'dowjones.com', '<', 'danielle.karwoski', '@', 'dowjones.com', '>', ';', 'skaszer', '@', 'hotmail.com', '<', 'skaszer', '@', 'hotmail.com', '>', ';', 'preventdk', '@', 'dellmail.com', '<', 'preventdk', '@', 'dellmail.com', '>', ';', 'leanne_michalek', '@', 'njb.uscourts.gov', '<', 'leanne_michalek', '@', 'njb.uscourts.gov', '>', ';', 'bposkitt', '@', 'sprintmail.com', '<', 'bposkitt', '@', 'sprintmail.com', '>', ';', 'kjposkitt', '@', 'aol.com', '<', 'kjposkitt', '@', 'aol.com', '>', ';', 'poskitt', '@', 'worldnet.att.net', '<', 'poskitt', '@', 'worldnet.att.net', '>', ';', 'msawatka', '@', 'hotmail.com', '<', 'msawatka', '@', 'hotmail.com', '>', ';', 's.schnitzer', '@', 'worldnet.att.net', '<', 's.schnitzer', '@', 'worldnet.att.net', '>', '>', '>', '>', '>', 'TIGHT', 'SKIRTS', 'AND', 'TEXANS', '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', 'In', 'crowded', 'city', 'crowded', 'bus', 'stop', ',', 'beautiful', '>', 'young', 'woman', 'waiting', 'bus', '.', 'She', 'decked', 'in', 'tight', '>', 'leather', 'mini', 'skirt', 'matching', 'tight', 'leather', 'boots', 'jacket', '.', '>', '>', 'As', 'bus', 'rolled', 'became', 'turn', 'get', ',', 'became', 'aware', '>', '>', 'skirt', 'too', 'tight', 'allow', 'leg', 'come', 'height', '>', 'first', 'step', '>', 'bus', '.', 'Slightly', 'embarrassed', ',', 'quick', 'smile', 'bus', '>', 'driver', ',', 'reached', 'behind', 'unzipped', 'skirt', 'little', ',', 'thinking', '>', 'would', 'give', 'enough', 'slack', 'raise', 'leg', '.', 'Again', 'tried', '>', 'make', 'step', 'bus', 'discover', 'still', '>', 'could', \"n't\", '.', '>', '>', 'So', ',', 'little', 'embarrassed', ',', 'once', 'reached', '>', 'behind', 'unzipped', 'skirt', 'little', 'and', ',', 'second', 'time', '>', 'attempted', 'step', '.', '>', 'Once', ',', 'much', 'chagrin', ',', 'could', 'raise', '>', 'leg', 'tight', 'skirt', '.', 'With', 'a', 'coy', 'little', 'smile', 'to', 'driver', ',', '>', '>', 'unzipped', 'the', 'offending', 'skirt', 'to', 'give', 'a', 'little', 'slack', 'and', 'again', '>', 'unable', 'to', 'make', 'the', 'step', '.', '>', '>', 'About', 'time', ',', 'the', 'big', 'Texan', 'behind', 'in', 'line', 'picked', '>', 'her', 'up', 'easily', 'the', 'waist', 'and', 'placed', 'her', 'lightly', 'the', 'top', 'step', 'of', '>', 'the', '>', '>', 'bus', '.', '>', 'She', 'went', 'absolutely', 'ballistic', 'and', 'turned', 'the', 'would-be', '>', 'hero', ',', 'screeching', 'him', '.', '``', 'How', 'dare', 'touch', 'body', '!', '!', '>', 'I', \"n't\", 'even', 'know', '>', '!', \"''\", '>', '>', 'At', 'this', ',', 'the', 'Texan', 'drawled', ',', '``', 'Well', \"Ma'am\", ',', 'normally', 'I', '>', 'would', 'agree', 'with', 'you', ',', 'after', 'you', 'unzipped', 'fly', 'three', 'times', ',', 'I', 'kinda', '>', 'figured', 'we', 'friends', '.', \"''\", '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', '>', '________________________________________________', '>', 'Do', 'You', 'Yahoo', '!', '?', '>', 'Get', 'free', '@', 'yahoo.com', 'address', 'http', ':', '//mail.yahoo.com', '>', '>']\n",
            "carson-m\n",
            "\t['What', 'up', '?', '?', 'What', 'think', 'the', 'cotton', 'bowl', '?', '?', '?', 'Are', 'you', 'going', '?', '?']\n",
            "\t['TIME', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', \"''\", 'Pape', ',', 'Travis', \"''\", '<', 'tpape', '@', 'satake-usa.com', '>', 'DATE', 'TIME', 'And', 'is', '!', 'It', \"'s\", 'about', 'he', 'said', ',', 'said', 'bullshit', '--', '--', '-Original', 'Message', '--', '--', '-', 'Are', 'guys', 'little', 'guys', 'night', 'tonight', '?', '?', 'Call', '713-853-6203', 'leave', 'message', 'for', 'me', 'home', '713-668-3712', '.']\n",
            "farmer-d\n",
            "\t['Can', 'come', 'desk', 'around', '1:00', '?', 'Enron', 'North', 'America', 'Corp.', 'From', ':', 'Megan', 'Parker', '@', 'ENRON', 'DATE', 'TIME', 'Do', 'time', 'afternoon', 'Monday', 'look', 'the', 'Tenaska', 'spreadsheet', '?', 'I', 'trying', 'to', 'close', 'Jan', '2001', 'I', 'have', 'some', 'questions', '.']\n",
            "\t['Charlene', ',', 'We', 'scheduled', 'volume', '29-30th', '.', 'No', 'price', 'negotiated', 'I', 'find', '.', 'However', ',', 'since', 'gas', 'flow', ',', 'I', 'rolled', 'last', 'price', 'deal', 'cover', 'days', '.', 'What', 'price', 'Hesco', 'showing', '?', 'DATE', 'TIME', 'Daren', 'would', 'look', 'price', '29', '30th', 'March', '2000', '.', 'There', 'no', 'prices', 'these', 'days', 'volume', 'scheduled', 'these', 'days', '.', 'Daren', 'J', 'Farmer', 'DATE', 'TIME', 'Charlene', ',', 'Deal', '#', '214948', 'already', 'volume', 'price', 'the', '12th', '13th', '.', 'You', 'may', 'need', 'the', 'volumes', 'updated', 'Volume', 'Management', '.', 'I', 'added', 'the', '15th', '16th', 'the', 'deal', 'ticket', '.', 'DATE', 'TIME', 'Hakemack/HOU/ECT', '@', 'ECT', 'Help', '.', 'Steve', 'Mauch', 'Hesco', 'wanting', 'answer', 'ASAP', 'TIME', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-', 'Vance', 'L', 'Taylor', 'DATE', 'TIME', 'This', 'gas', 'purchase', 'not', 'part', 'the', 'wellhead', 'portfolio', 'traded', 'the', 'Texas', 'desk', '.', 'I', 'would', 'suggest', 'get', 'Darren', 'Farmer', 'someone', 'the', 'desk', '.', 'Sorry', 'I', 'could', 'not', 'be', 'more', 'assistance', '!', 'x3-6353', 'DATE', 'TIME', 'Meter', '986725', 'March', '2000', '.', 'Per', 'Hesco', 'traders', 'gone', '(', 'Hesco', 'Enron', ')', '(', 'Hesco', ')', 'not', 'paid', 'the', 'correct', 'price', 'March', 'the', 'days', 'mentioned', '.', 'Hesco', 'not', 'find', 'the', 'price', 'these', 'days', 'recorded', '.', 'Per', 'Hesco', 'were', 'underpaid', '$', '32,101.57', '.', 'Hesco', 'is', 'wanting', 'come', 'our', 'office', 'have', 'meeting', 'clearing', 'up', '.', 'It', 'be', 'nice', 'we', \"n't\", 'have', 'to', 'meet', 'them', '.', 'Production', 'dates', 'Volume', 'price', 'they', 'are', 'looking', '03/12', '2,029', '2.65', '03/13', '2,009', '2.65', '03/15', '2,022', '2.71', '03/16', '1,976', '2.72']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING / TESTING SPLIT**"
      ],
      "metadata": {
        "id": "coM4C2cogurg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separate train/test data, define as token lists\n",
        "train_test_ratio = 0.9 # e.g., for 100 emails, 90 are training and 10 are testing\n",
        "\n",
        "authors_training_tokenized_emails = {}\n",
        "authors_testing_tokenized_emails = {}\n",
        "for author in project_authors:\n",
        "  emails = authors_tokenized_emails[author]\n",
        "  num_emails = len(emails)\n",
        "  training_cutoff = math.floor(train_test_ratio * num_emails)\n",
        "  training = emails[:training_cutoff]\n",
        "  testing  = emails[training_cutoff:]\n",
        "  print(author, num_emails, len(training), len(testing))\n",
        "  authors_training_tokenized_emails[author] = training\n",
        "  authors_testing_tokenized_emails[author] = testing\n",
        "\n",
        "print()\n",
        "print(\"all emails:  \\t\", sum(len(authors_tokenized_emails[author]) for author in project_authors))\n",
        "print(\"all training:\\t\", sum(len(authors_training_tokenized_emails[author]) for author in project_authors))\n",
        "print(\"all testing: \\t\", sum(len(authors_testing_tokenized_emails[author]) for author in project_authors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf5abcc-787a-43f4-bdc9-e93f6980dfe3",
        "id": "7OSCgHF7guri"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allen-p 602 541 61\n",
            "bass-e 1409 1268 141\n",
            "buy-r 165 148 17\n",
            "delainey-d 875 787 88\n",
            "fossum-d 1099 989 110\n",
            "arnold-j 814 732 82\n",
            "beck-s 1093 983 110\n",
            "campbell-l 200 180 20\n",
            "badeer-r 52 46 6\n",
            "brawner-s 145 130 15\n",
            "carson-m 172 154 18\n",
            "farmer-d 747 672 75\n",
            "\n",
            "all emails:  \t 7373\n",
            "all training:\t 6630\n",
            "all testing: \t 743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROCESS TRAINING EMAILS**"
      ],
      "metadata": {
        "id": "3ntNbx9jg7ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for each author, join all email tokens into one list\n",
        "EMAIL_START_TOK = \"EMAIL-START\"\n",
        "EMAIL_END_TOK = \"EMAIL-END\"\n",
        "\n",
        "author_tokens = {}\n",
        "for author in project_authors:\n",
        "  all_email_tokens = []\n",
        "  for email_token_list in authors_training_tokenized_emails[author]:\n",
        "    all_email_tokens.append(EMAIL_START_TOK)\n",
        "    all_email_tokens.extend(email_token_list)\n",
        "    all_email_tokens.append(EMAIL_END_TOK)\n",
        "  author_tokens[author] = all_email_tokens\n",
        "\n",
        "# DEBUG OUTPUT\n",
        "print(\"SAMPLE\")\n",
        "for author in project_authors:\n",
        "  all_email_tokens = author_tokens[author]\n",
        "  print(author, all_email_tokens[0:20])"
      ],
      "metadata": {
        "id": "A-25w9Vc-_ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e51edcb3-93bc-4cf6-bf6a-c23f96433fc1"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE\n",
            "allen-p ['EMAIL-START', 'Here', 'our', 'forecast', 'EMAIL-END', 'EMAIL-START', 'You', 'wrote', 'fewer', 'checks', 'month', '.', 'Spent', 'money', 'Materials', 'less', 'Labor', '.', 'June', 'July']\n",
            "bass-e ['EMAIL-START', 'From', ':', 'Larry', 'Joe', 'Hunter', 'DATE', 'TIME', 'Can', 'adjust', 'TAGG', 'shortname', 'MIRANTAMEENE', '(', 'currently', 'MIRANTAMEENECAN', ')', '?', 'EMAIL-END', 'EMAIL-START']\n",
            "buy-r ['EMAIL-START', 'ted.murphy', '@', 'enron.com', ',', 'mark.ruane', '@', 'enron.com', ',', 'steve.young', '@', 'enron.com', 'pam.metoyer', '@', 'enron.com', ',', 'rita.hennessy', '@', 'enron.com', ',']\n",
            "delainey-d ['EMAIL-START', 'brian.redmond', '@', 'enron.com', ',', 'max.yzaguirre', '@', 'enron.com', ',', 'rob.milnthorp', '@', 'enron.com', 'Guys', ',', 'details', 'the', 'ESA', 'MEH', 'turbines', '-']\n",
            "fossum-d ['EMAIL-START', 'Dammit', 'Jenkins', ',', \"n't\", 'even', 'joke', 'stuff', 'like', '!', 'If', 'market', 'ever', 'realized', 'I', 'worked', ',', 'stock', 'would', 'go']\n",
            "arnold-j ['EMAIL-START', 'saw', 'lot', 'bulls', 'sell', 'summer', 'length', 'front', 'mitigate', 'margins/absolute', 'position', 'limits/var', '.', 'guys', 'taking', 'front', ',', 'also', 'buying', 'back']\n",
            "beck-s ['EMAIL-START', 'Thanks', 'rounding', 'tickets', 'Orange', 'Bowl', '.', 'You', 'mail', ',', 'hold', 'until', 'I', 'see', 'Christmas', '.', 'Mike', \"'s\", 'wife', 'decided']\n",
            "campbell-l ['EMAIL-START', 'The', 'third', 'quarter', 'PCB', 'meeting', 'Southern', 'California', 'Gas', 'Company', 'held', 'morning', '.', 'SoCal', 'presented', 'third', 'quarter', 'invoce', 'their', 'PCB']\n",
            "badeer-r ['EMAIL-START', 'mitch.mcclintock', '@', 'enron.com', 'I', 'be', 'of', 'office', 'Friday', ',', 'Monday', 'Tuesday', 'vacation', '.', 'I', 'be', 'able', 'be', 'reached', 'cell']\n",
            "brawner-s ['EMAIL-START', '``', 'Jon', 'Schnitzer', \"''\", '<', 'jons', '@', 'amerexenergy.com', '>', 'DATE', 'TIME', '>', '>', '>', '>', '>', 'A', 'priest', 'took']\n",
            "carson-m ['EMAIL-START', 'What', 'up', '?', '?', 'What', 'think', 'the', 'cotton', 'bowl', '?', '?', '?', 'Are', 'you', 'going', '?', '?', 'EMAIL-END', 'EMAIL-START']\n",
            "farmer-d ['EMAIL-START', 'Can', 'come', 'desk', 'around', '1:00', '?', 'Enron', 'North', 'America', 'Corp.', 'From', ':', 'Megan', 'Parker', '@', 'ENRON', 'DATE', 'TIME', 'Do']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROCESSING BIGRAMS**"
      ],
      "metadata": {
        "id": "Q4lzbNJjnbpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for each author, compute bigrams\n",
        "author_bigrams = {}\n",
        "for author in project_authors:\n",
        "  author_bigrams[author] = list(bigrams(author_tokens[author]))\n",
        "\n",
        "# DEBUG OUTPUT\n",
        "print(\"SAMPLE\")\n",
        "for author in project_authors:\n",
        "  all_bigrams = author_bigrams[author]\n",
        "  print(author, all_bigrams[0:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ5TboHRja06",
        "outputId": "34db2624-52c1-4389-f145-3782b77d364e"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE\n",
            "allen-p [('EMAIL-START', 'Here'), ('Here', 'our'), ('our', 'forecast'), ('forecast', 'EMAIL-END'), ('EMAIL-END', 'EMAIL-START'), ('EMAIL-START', 'You'), ('You', 'wrote'), ('wrote', 'fewer'), ('fewer', 'checks'), ('checks', 'month'), ('month', '.'), ('.', 'Spent'), ('Spent', 'money'), ('money', 'Materials'), ('Materials', 'less'), ('less', 'Labor'), ('Labor', '.'), ('.', 'June'), ('June', 'July'), ('July', 'August')]\n",
            "bass-e [('EMAIL-START', 'From'), ('From', ':'), (':', 'Larry'), ('Larry', 'Joe'), ('Joe', 'Hunter'), ('Hunter', 'DATE'), ('DATE', 'TIME'), ('TIME', 'Can'), ('Can', 'adjust'), ('adjust', 'TAGG'), ('TAGG', 'shortname'), ('shortname', 'MIRANTAMEENE'), ('MIRANTAMEENE', '('), ('(', 'currently'), ('currently', 'MIRANTAMEENECAN'), ('MIRANTAMEENECAN', ')'), (')', '?'), ('?', 'EMAIL-END'), ('EMAIL-END', 'EMAIL-START'), ('EMAIL-START', \"o'neal.winfree\")]\n",
            "buy-r [('EMAIL-START', 'ted.murphy'), ('ted.murphy', '@'), ('@', 'enron.com'), ('enron.com', ','), (',', 'mark.ruane'), ('mark.ruane', '@'), ('@', 'enron.com'), ('enron.com', ','), (',', 'steve.young'), ('steve.young', '@'), ('@', 'enron.com'), ('enron.com', 'pam.metoyer'), ('pam.metoyer', '@'), ('@', 'enron.com'), ('enron.com', ','), (',', 'rita.hennessy'), ('rita.hennessy', '@'), ('@', 'enron.com'), ('enron.com', ','), (',', 'denise.naiser')]\n",
            "delainey-d [('EMAIL-START', 'brian.redmond'), ('brian.redmond', '@'), ('@', 'enron.com'), ('enron.com', ','), (',', 'max.yzaguirre'), ('max.yzaguirre', '@'), ('@', 'enron.com'), ('enron.com', ','), (',', 'rob.milnthorp'), ('rob.milnthorp', '@'), ('@', 'enron.com'), ('enron.com', 'Guys'), ('Guys', ','), (',', 'details'), ('details', 'the'), ('the', 'ESA'), ('ESA', 'MEH'), ('MEH', 'turbines'), ('turbines', '-'), ('-', 'please')]\n",
            "fossum-d [('EMAIL-START', 'Dammit'), ('Dammit', 'Jenkins'), ('Jenkins', ','), (',', \"n't\"), (\"n't\", 'even'), ('even', 'joke'), ('joke', 'stuff'), ('stuff', 'like'), ('like', '!'), ('!', 'If'), ('If', 'market'), ('market', 'ever'), ('ever', 'realized'), ('realized', 'I'), ('I', 'worked'), ('worked', ','), (',', 'stock'), ('stock', 'would'), ('would', 'go'), ('go', '$')]\n",
            "arnold-j [('EMAIL-START', 'saw'), ('saw', 'lot'), ('lot', 'bulls'), ('bulls', 'sell'), ('sell', 'summer'), ('summer', 'length'), ('length', 'front'), ('front', 'mitigate'), ('mitigate', 'margins/absolute'), ('margins/absolute', 'position'), ('position', 'limits/var'), ('limits/var', '.'), ('.', 'guys'), ('guys', 'taking'), ('taking', 'front'), ('front', ','), (',', 'also'), ('also', 'buying'), ('buying', 'back'), ('back', 'summer')]\n",
            "beck-s [('EMAIL-START', 'Thanks'), ('Thanks', 'rounding'), ('rounding', 'tickets'), ('tickets', 'Orange'), ('Orange', 'Bowl'), ('Bowl', '.'), ('.', 'You'), ('You', 'mail'), ('mail', ','), (',', 'hold'), ('hold', 'until'), ('until', 'I'), ('I', 'see'), ('see', 'Christmas'), ('Christmas', '.'), ('.', 'Mike'), ('Mike', \"'s\"), (\"'s\", 'wife'), ('wife', 'decided'), ('decided', 'make')]\n",
            "campbell-l [('EMAIL-START', 'The'), ('The', 'third'), ('third', 'quarter'), ('quarter', 'PCB'), ('PCB', 'meeting'), ('meeting', 'Southern'), ('Southern', 'California'), ('California', 'Gas'), ('Gas', 'Company'), ('Company', 'held'), ('held', 'morning'), ('morning', '.'), ('.', 'SoCal'), ('SoCal', 'presented'), ('presented', 'third'), ('third', 'quarter'), ('quarter', 'invoce'), ('invoce', 'their'), ('their', 'PCB'), ('PCB', 'management')]\n",
            "badeer-r [('EMAIL-START', 'mitch.mcclintock'), ('mitch.mcclintock', '@'), ('@', 'enron.com'), ('enron.com', 'I'), ('I', 'be'), ('be', 'of'), ('of', 'office'), ('office', 'Friday'), ('Friday', ','), (',', 'Monday'), ('Monday', 'Tuesday'), ('Tuesday', 'vacation'), ('vacation', '.'), ('.', 'I'), ('I', 'be'), ('be', 'able'), ('able', 'be'), ('be', 'reached'), ('reached', 'cell'), ('cell', 'phone')]\n",
            "brawner-s [('EMAIL-START', '``'), ('``', 'Jon'), ('Jon', 'Schnitzer'), ('Schnitzer', \"''\"), (\"''\", '<'), ('<', 'jons'), ('jons', '@'), ('@', 'amerexenergy.com'), ('amerexenergy.com', '>'), ('>', 'DATE'), ('DATE', 'TIME'), ('TIME', '>'), ('>', '>'), ('>', '>'), ('>', '>'), ('>', '>'), ('>', 'A'), ('A', 'priest'), ('priest', 'took'), ('took', 'sebatacle')]\n",
            "carson-m [('EMAIL-START', 'What'), ('What', 'up'), ('up', '?'), ('?', '?'), ('?', 'What'), ('What', 'think'), ('think', 'the'), ('the', 'cotton'), ('cotton', 'bowl'), ('bowl', '?'), ('?', '?'), ('?', '?'), ('?', 'Are'), ('Are', 'you'), ('you', 'going'), ('going', '?'), ('?', '?'), ('?', 'EMAIL-END'), ('EMAIL-END', 'EMAIL-START'), ('EMAIL-START', 'TIME')]\n",
            "farmer-d [('EMAIL-START', 'Can'), ('Can', 'come'), ('come', 'desk'), ('desk', 'around'), ('around', '1:00'), ('1:00', '?'), ('?', 'Enron'), ('Enron', 'North'), ('North', 'America'), ('America', 'Corp.'), ('Corp.', 'From'), ('From', ':'), (':', 'Megan'), ('Megan', 'Parker'), ('Parker', '@'), ('@', 'ENRON'), ('ENRON', 'DATE'), ('DATE', 'TIME'), ('TIME', 'Do'), ('Do', 'time')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for each author, compute bigram (relative) frequencies\n",
        "\n",
        "author_bigram_frequencies = {}\n",
        "for author in project_authors:\n",
        "  # get count\n",
        "  bigram_counter = Counter(author_bigrams[author])\n",
        "  # get rel. freq's\n",
        "  num_bigrams = sum(bigram_counter.values())\n",
        "  bigram_rel_frequency = Counter({bigram:freq/num_bigrams for bigram, freq in bigram_counter.items()})\n",
        "  author_bigram_frequencies[author] = bigram_rel_frequency\n",
        "\n",
        "\n",
        "print(\"SAMPLE\")\n",
        "print(\"Top-20 most common bigrams:\")\n",
        "for author in project_authors:\n",
        "  bigram_freqs = author_bigram_frequencies[author]\n",
        "  print(author, bigram_freqs.most_common()[0:20])\n",
        "\n",
        "print()\n",
        "print(\"Middle-X most common bigrams:\")\n",
        "for author in project_authors:\n",
        "  bigram_freqs = author_bigram_frequencies[author]\n",
        "  print(author, bigram_freqs.most_common()[100:120])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KSyteeLlppG",
        "outputId": "330be650-9acc-4f60-c01d-6a8926ef78dc"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE\n",
            "Top-20 most common bigrams:\n",
            "allen-p [(('--', '--'), 0.041531894781928015), (('@', 'ECT'), 0.012480245764839677), (('ECT', ','), 0.011505457338236814), (('EMAIL-END', 'EMAIL-START'), 0.007975541672205237), (('@', 'ENRON'), 0.005878269602847564), (('ENRON', ','), 0.005449953476006912), (('.', 'I'), 0.00508071543562704), (('.', 'EMAIL-END'), 0.004268391746791321), (('*', '*'), 0.00378099753348989), (('@', 'Enron'), 0.0036480718389531363), (('--', '-'), 0.0033526814066492387), (('Enron', ','), 0.0032492947553428744), (('.', 'The'), 0.003219755712112485), (('DATE', 'TIME'), 0.00314590810403651), (('TIME', '--'), 0.0029834433662693665), (('@', 'EES'), 0.002939134801423782), (('EES', ','), 0.002924365279808587), (('@', 'EnronXGate'), 0.002555127239428715), (('EnronXGate', ','), 0.00254035771781352), (('EMAIL-START', 'TIME'), 0.0021120415909728686)]\n",
            "bass-e [(('--', '--'), 0.03588527915095367), (('>', '>'), 0.02824967190750126), (('*', '*'), 0.011100679008823484), (('@', 'ECT'), 0.010089168538393306), (('ECT', ','), 0.008776798543424922), (('DATE', 'TIME'), 0.00667596910483917), (('EMAIL-END', 'EMAIL-START'), 0.006572224441205306), (('@', 'enron.com'), 0.005726705432589311), ((\"''\", '<'), 0.005130173616694591), (('>', ','), 0.003828178088089594), (('enron.com', ','), 0.0037555568235458888), (('--', '-'), 0.0035532547294598532), (('.', 'I'), 0.0032679569044667266), (('From', ':'), 0.0025988038240283015), (('@', 'Enron'), 0.002583242124483222), ((',', '``'), 0.0024950591603944373), (('@', 'ENRON'), 0.0023083187658534815), (('.', '>'), 0.0022616336672182423), (('>', 'DATE'), 0.0022408847344914697), ((',', 'I'), 0.0022356975013097763)]\n",
            "buy-r [(('--', '--'), 0.0467695274831244), (('EMAIL-END', 'EMAIL-START'), 0.011812921890067503), (('@', 'ECT'), 0.010768241722918676), (('ECT', ','), 0.009241401478624237), (('.', 'I'), 0.006107360977177756), (('@', 'Enron'), 0.005946640951462552), (('Enron', ','), 0.0048216007714561235), (('Rick', 'EMAIL-END'), 0.004500160720025715), (('@', 'ENRON'), 0.004339440694310511), (('--', '-'), 0.004098360655737705), (('DATE', 'TIME'), 0.004098360655737705), (('.', 'EMAIL-END'), 0.0037769206043072965), (('ENRON', ','), 0.0036965605914496946), (('@', 'enron.com'), 0.0032144005143040825), (('.', 'Rick'), 0.00313404050144648), (('.', 'The'), 0.00233044037287046), (('.', '-'), 0.0021697203471552555), (('.', 'We'), 0.0020893603342976535), (('.', 'Thanks'), 0.0020090003214400516), (('@', 'EES'), 0.0018482802957248473)]\n",
            "delainey-d [(('--', '--'), 0.04948204335125316), (('@', 'enron.com'), 0.019202444951763754), (('enron.com', ','), 0.017011561970690037), (('@', 'ECT'), 0.01086236099860078), (('ECT', ','), 0.009757714117387142), (('@', 'Enron'), 0.005001595601050642), (('EMAIL-END', 'EMAIL-START'), 0.004823624714632889), (('DATE', 'TIME'), 0.004369492107911726), (('Enron', ','), 0.004087193460490463), (('--', '-'), 0.0040810565333726095), (('.', 'I'), 0.004056508824901195), (('TIME', '--'), 0.003737388614772811), ((',', 'I'), 0.0032157498097552593), (('.', 'EMAIL-END'), 0.003056189704691067), (('.', 'The'), 0.002687974077619854), (('@', 'ENRON'), 0.0025345508996735154), (('*', '*'), 0.0023688538674914695), (('.', 'TIME'), 0.002025185948891671), (('ENRON', ','), 0.0018533519895917716), (('I', 'would'), 0.0016692441760561652)]\n",
            "fossum-d [(('--', '--'), 0.028543706749530898), (('@', 'ENRON'), 0.01631068957116051), (('ENRON', ','), 0.014241933346726108), (('&', 'S/Enron'), 0.013241749552268152), (('S/Enron', '@'), 0.013062229384032108), (('DATE', 'TIME'), 0.004671798663857033), (('EMAIL-END', 'EMAIL-START'), 0.004222998243266925), (('@', 'enron.com'), 0.0039152493834337075), (('.', 'I'), 0.0037143577665981354), (('--', '-'), 0.002915065588975752), (('>', '>'), 0.0026115910188624406), (('.', 'The'), 0.002410699402026868), (('enron.com', ','), 0.0024021508225870567), ((',', 'I'), 0.002350859345948187), (('@', 'Enron'), 0.002201259205751484), (('.', 'DF'), 0.0021328705702329917), (('@', 'enronXgate'), 0.002068756224434405), (('TIME', '--'), 0.0020089161683557234), (('enronXgate', ','), 0.0019618989814367597), (('.', 'EMAIL-END'), 0.001936253243117325)]\n",
            "arnold-j [(('--', '--'), 0.028660288559570764), (('*', '*'), 0.012584575141859674), (('EMAIL-END', 'EMAIL-START'), 0.007528088730523259), (('DATE', 'TIME'), 0.006632132889818028), (('@', 'ECT'), 0.005169768184299146), (('ECT', ','), 0.004448884174536317), ((\"''\", '<'), 0.003635315077803981), (('.', 'I'), 0.0028423426670648694), (('--', '-'), 0.0028217459810716454), (('>', ','), 0.002389215575213948), (('.', 'EMAIL-END'), 0.002131757000298652), ((')', \"''\"), 0.0020802652853155927), (('.', 'The'), 0.0020287735703325336), (('(', 'E-mail'), 0.0020287735703325336), ((',', '``'), 0.0020081768843393097), (('E-mail', ')'), 0.001987580198346086), (('@', 'Enron'), 0.0019051934543731913), (('@', 'ENRON'), 0.0019051934543731913), (('>', 'DATE'), 0.0017095249374375664), (('?', '?'), 0.0016374365364612833)]\n",
            "beck-s [(('--', '--'), 0.026395934139293736), (('@', 'ECT'), 0.014710970124889753), (('ECT', ','), 0.013677937443049201), (('@', 'enron.com'), 0.012976254866704675), (('enron.com', ','), 0.011928603797856945), (('.', 'I'), 0.007796473070494735), (('EMAIL-END', 'EMAIL-START'), 0.004785085347016144), (('DATE', 'TIME'), 0.004570682337577538), (('@', 'ENRON'), 0.00388361814824019), (('@', 'Enron'), 0.0035473952470751044), ((',', 'I'), 0.003216045141579078), (('Enron', ','), 0.00277262073569469), (('ENRON', ','), 0.002704401596327861), (('.', 'EMAIL-END'), 0.0024753801998820785), (('.', '--'), 0.0023633058994937165), (('--', '-'), 0.0022950867601268876), (('--', 'Sally'), 0.0020904293420264007), (('.', 'We'), 0.0019150086979402693), (('*', '*'), 0.0018662807412496772), (('.', 'The'), 0.0015203122487464733)]\n",
            "campbell-l [(('--', '--'), 0.018724611874686995), (('*', '*'), 0.011991541928662846), (('>', ','), 0.011935896722497357), (('>', '>'), 0.010878637805353069), ((\"''\", '<'), 0.009821378888208781), ((',', '``'), 0.007039118579934339), (('@', 'enron.com'), 0.006677424739858661), (('@', 'Enron'), 0.005842746647376328), (('=01', ';'), 0.005230649379555951), (('EMAIL-END', 'EMAIL-START'), 0.004980245951811252), ((\"'\", \"''\"), 0.004729842524066552), (('enron.com', ','), 0.004451616493239108), (('@', 'ECT'), 0.00408992265316343), ((';', '=01'), 0.004062100050080685), (('ECT', ','), 0.004006454843915197), (('@', 'hotmail.com'), 0.003700406210005008), (('Enron', ','), 0.0034778253853430525), (('@', 'aol.com'), 0.0031995993545156083), (('http', ':'), 0.002726615102108953), (('hotmail.com', ','), 0.0024762116743642535)]\n",
            "badeer-r [(('--', '--'), 0.0339583640927211), (('>', ','), 0.016388601801269748), ((\"''\", '<'), 0.015059796249815443), ((',', '``'), 0.012402185146906835), (('EMAIL-END', 'EMAIL-START'), 0.006644027757271519), (('(', 'E-mail'), 0.005462867267089916), (('E-mail', ')'), 0.005462867267089916), ((')', \"''\"), 0.005167577144544515), (('.', '('), 0.005167577144544515), (('.', 'He'), 0.003691126531817511), (('.', 'The'), 0.003100546286726709), (('DATE', 'TIME'), 0.003100546286726709), (('@', 'EES'), 0.003100546286726709), (('--', '-'), 0.0029529012254540087), (('.', 'EMAIL-END'), 0.0026576111029086077), ((',', '2000'), 0.0026576111029086077), (('@', 'ECT'), 0.002509966041635907), (('EES', ','), 0.002362320980363207), ((',', \"''\"), 0.002067030857817806), (('@', 'caiso.com'), 0.002067030857817806)]\n",
            "brawner-s [(('>', '>'), 0.1964970744371682), (('--', '--'), 0.025961948308598444), (('.', '>'), 0.014065951098539156), ((\"''\", '<'), 0.010811020265819352), (('*', '*'), 0.010074785910799395), (('>', ','), 0.007982330375479522), ((',', '``'), 0.007633587786259542), (('EMAIL-END', 'EMAIL-START'), 0.0049986437788197), (('.', 'I'), 0.004882396249079707), ((',', '>'), 0.0030611849498198163), (('--', '-'), 0.0030224357732398185), (('>', 'TIME'), 0.0025574456542798467), ((\"''\", '>'), 0.0022862014182198627), (('>', ';'), 0.0022862014182198627), (('!', '!'), 0.0022474522416398653), (('>', 'To'), 0.002053706358739877), (('@', 'ECT'), 0.002053706358739877), (('ECT', ','), 0.002053706358739877), (('>', 'You'), 0.0019374588289998837), (('@', 'aol.com'), 0.001898709652419886)]\n",
            "carson-m [(('--', '--'), 0.0495431733367649), (('*', '*'), 0.041178741474713676), (('>', '>'), 0.03345772744820486), (('EMAIL-END', 'EMAIL-START'), 0.019688585767597477), (('?', '?'), 0.011066786771329301), ((',', ','), 0.011066786771329301), (('!', '!'), 0.007463646892291854), (('>', ','), 0.005919444086990092), (('!', 'EMAIL-END'), 0.004761291983013769), (('--', '-'), 0.004503924848796808), ((\"''\", '<'), 0.004375241281688328), (('DATE', 'TIME'), 0.004246557714579848), (('?', 'EMAIL-END'), 0.003989190580362888), (('TIME', '--'), 0.003603139879037447), (('http', ':'), 0.003603139879037447), (('EMAIL-START', 'TIME'), 0.0032170891777120064), (('@', 'aol.com'), 0.0028310384763865653), (('.', '>'), 0.0028310384763865653), (('.', 'I'), 0.0027023549092780852), (('@', 'hotmail.com'), 0.0027023549092780852)]\n",
            "farmer-d [(('--', '--'), 0.04698705024007982), (('@', 'ECT'), 0.017990396807250203), (('ECT', ','), 0.015267413581658318), (('DATE', 'TIME'), 0.009384938369120122), (('EMAIL-END', 'EMAIL-START'), 0.006973747115924255), (('>', '>'), 0.005903261344031263), (('.', 'I'), 0.0047288449146729306), (('@', 'ENRON'), 0.0041052609698808955), (('--', '-'), 0.004074081772641294), (('.', 'EMAIL-END'), 0.00382464819472448), ((',', 'I'), 0.003076347460974038), (('.', 'The'), 0.002962023737762165), (('ENRON', ','), 0.002754162422831487), (('TIME', '--'), 0.002608659502380012), (('From', ':'), 0.0025566941736473426), (('@', 'Enron'), 0.0024527635161820036), (('Enron', ','), 0.002140971543785986), (('.', 'DATE'), 0.0020786131493067826), (('@', 'enron.com'), 0.0020786131493067826), (('.', 'Thanks'), 0.0019227171631087739)]\n",
            "\n",
            "Middle-X most common bigrams:\n",
            "allen-p [((':', 'Phillip'), 0.0003692380403798721), (('year', '.'), 0.0003544685187646772), (('Please', 'respond'), 0.0003544685187646772), ((')', ','), 0.0003544685187646772), (('.', 'There'), 0.0003544685187646772), (('.', '#'), 0.0003544685187646772), (('-', 'basis'), 0.0003544685187646772), (('let', 'know'), 0.00033969899714948233), (('However', ','), 0.00033969899714948233), (('EMAIL-START', 'The'), 0.00033969899714948233), (('To', ':'), 0.00033969899714948233), (('time', '.'), 0.00032492947553428746), (('Let', 'know'), 0.00032492947553428746), (('.', 'They'), 0.00032492947553428746), ((',', 'Chris'), 0.00032492947553428746), (('Sent', ':'), 0.00032492947553428746), (('San', 'Marcos'), 0.00032492947553428746), (('(', '$'), 0.00032492947553428746), ((',', 'Jim'), 0.00032492947553428746), ((',', '='), 0.00032492947553428746)]\n",
            "bass-e [(('TIME', 'I'), 0.0005394722508960945), (('?', '>'), 0.0005342850177144014), (('TIME', 'Please'), 0.0005342850177144014), (('.', 'But'), 0.0005290977845327081), (('>', ';'), 0.0005290977845327081), ((':', '>'), 0.0005239105513510149), (('.', 'Please'), 0.0005239105513510149), (('ca', \"n't\"), 0.0005187233181693216), (('Hull/HOU/ECT', '@'), 0.0005187233181693216), (('<', 'lwbthemarine'), 0.0005135360849876285), ((',', 'please'), 0.0005135360849876285), (('=09', '?'), 0.0005135360849876285), (('respond', '``'), 0.0005083488518059352), (('Bass/HOU/ECT', '@'), 0.000503161618624242), ((',', 'Eric'), 0.0004979743854425488), (('Re', ':'), 0.0004979743854425488), (('.', 'He'), 0.0004927871522608556), ((',', 'David'), 0.00048759991907916235), (('would', 'like'), 0.00048759991907916235), (('-', 'Enron'), 0.0004824126858974691)]\n",
            "buy-r [(('Rick', ','), 0.00048216007714561236), ((',', 'John'), 0.00048216007714561236), ((')', '-'), 0.00048216007714561236), (('issue', '.'), 0.00048216007714561236), (('Enron', '.'), 0.00048216007714561236), (('the', 'right'), 0.0004018000642880103), (('right', 'person'), 0.0004018000642880103), (('?', 'rick'), 0.0004018000642880103), (('Market', 'Risk'), 0.0004018000642880103), (('.', 'Steve'), 0.0004018000642880103), (('would', 'like'), 0.0004018000642880103), (('tomorrow', '.'), 0.0004018000642880103), (('.', 'Lets'), 0.0004018000642880103), (('Sheila', 'Walton'), 0.0004018000642880103), (('Walton', 'DATE'), 0.0004018000642880103), (('I', 'heard'), 0.0004018000642880103), (('I', \"'ll\"), 0.0004018000642880103), (('well', '.'), 0.0004018000642880103), (('Bill', 'Bradford'), 0.0004018000642880103), (('I', 'know'), 0.0004018000642880103)]\n",
            "delainey-d [((',', 'James'), 0.00032525713724623805), (('Enron', \"'s\"), 0.000312983283010531), (('If', 'have'), 0.000312983283010531), ((',', 'you'), 0.0003068463558926774), (('Dave', ','), 0.0003068463558926774), (('b', ')'), 0.0003007094287748239), (('Sent', ':'), 0.0003007094287748239), (('EMAIL-START', 'Guys'), 0.0003007094287748239), (('.', '``'), 0.0003007094287748239), (('kay.chapman', '@'), 0.0002945725016569703), ((',', 'are'), 0.0002945725016569703), (('John', 'J'), 0.0002945725016569703), (('have', 'questions'), 0.0002945725016569703), ((',', 'Jeffrey'), 0.0002945725016569703), ((',', 'kay.chapman'), 0.0002884355745391168), (('1', '.'), 0.0002884355745391168), (('christy.chapman', '@'), 0.00028229864742126325), ((',', 'Jeff'), 0.00028229864742126325), (('Lavorato/Corp/Enron', '@'), 0.00028229864742126325), ((',', 'john.lavorato'), 0.00027616172030340967)]\n",
            "fossum-d [(('Enron', 'Communications'), 0.0004060575233910505), (('Hass/ET', '&'), 0.00039750894395123893), (('>', 'DATE'), 0.0003932346542313331), ((',', 'James'), 0.0003846860747915215), (('I', 'would'), 0.0003846860747915215), (('Vice', 'President'), 0.0003804117850716157), ((',', 'Robert'), 0.0003761374953517099), (('.', '('), 0.0003761374953517099), (('his', 'new'), 0.0003761374953517099), ((',', 'currently'), 0.0003761374953517099), (('Steven', 'Harris/ET'), 0.0003718632056318041), ((',', 'Michael'), 0.0003718632056318041), (('Managing', 'Director'), 0.0003675889159118983), (('President', 'General'), 0.0003675889159118983), (('natural', 'gas'), 0.00036331462619199257), (('Enron', '.'), 0.00035904033647208677), (('Sent', ':'), 0.00035476604675218097), (('EMAIL-START', 'Thanks'), 0.00034621746731236937), (('&', 'S'), 0.00034621746731236937), ((',', 'Glen'), 0.00034621746731236937)]\n",
            "arnold-j [(('To', ':'), 0.00038103869087463825), (('ce', 'message'), 0.00038103869087463825), (('$', '1'), 0.00037074034787802645), (('Communications', ','), 0.00037074034787802645), (('@', 'carrfut.com'), 0.0003604420048814146), (('.', 'So'), 0.00035014366188480274), (('contained', 'herein'), 0.00035014366188480274), (('.', 'As'), 0.00035014366188480274), (('EMAIL-START', 'AM'), 0.00035014366188480274), (('TIME', '--'), 0.00035014366188480274), (('.', '--'), 0.0003398453188881909), ((',', 'we'), 0.0003398453188881909), (('Arnold/HOU/ECT', '@'), 0.0003398453188881909), (('EMAIL-START', 'I'), 0.00032954697589157903), (('.', '>'), 0.00032954697589157903), (('-', \"''\"), 0.00032954697589157903), (('today', '.'), 0.00032954697589157903), (('Carr', 'Futures'), 0.00032954697589157903), (('cc', ':'), 0.00032954697589157903), (('I', \"n't\"), 0.0003192486328949672)]\n",
            "beck-s [(('I', 'not'), 0.0004239332232081512), (('I', 'will'), 0.000419060427539092), (('Tax', ')'), 0.000419060427539092), (('-', 'TIME'), 0.0004141876318700328), (('Sally', 'DATE'), 0.0004044420405319144), (('in', 'the'), 0.0004044420405319144), (('Let', 'know'), 0.00039956924486285515), (('know', '.'), 0.000394696449193796), ((',', 'Enron'), 0.000394696449193796), ((',', 'we'), 0.000394696449193796), (('-', 'I'), 0.000394696449193796), (('last', 'week'), 0.00038982365352473674), (('know', 'you'), 0.00038495085785567756), (('you', 'have'), 0.00038495085785567756), (('be', 'able'), 0.0003800780621866183), (('the', 'following'), 0.0003800780621866183), (('EWS', ')'), 0.0003800780621866183), (('Energy', 'Operations'), 0.00037520526651755914), ((\"''\", '<'), 0.0003703324708484999), (('!', 'I'), 0.0003703324708484999)]\n",
            "campbell-l [(('>', '<'), 0.0005008068554893996), (('.', 'A'), 0.00047298425240665517), (('>', 'To'), 0.00047298425240665517), (('reliantenergy.com', ','), 0.00047298425240665517), ((',', 'John'), 0.00047298425240665517), (('.', ')'), 0.00047298425240665517), ((',', 'please'), 0.00047298425240665517), (('(', '1'), 0.00047298425240665517), (('1', ')'), 0.00047298425240665517), ((\"''\", '>'), 0.00047298425240665517), (('View', 'pictures'), 0.00047298425240665517), (('air', 'permit'), 0.00044516164932391074), (('4', '.'), 0.00044516164932391074), (('@', 'dynegy.com'), 0.00044516164932391074), (('*', 'TRADE'), 0.00044516164932391074), (('>', 'From'), 0.0004173390462411663), (('@', 'enronXgate'), 0.0004173390462411663), (('Region', 'IX'), 0.0004173390462411663), ((',', 'Larry'), 0.0004173390462411663), (('New', 'Mexico'), 0.0004173390462411663)]\n",
            "badeer-r [(('Kaufman/PDX/ECT', '@'), 0.0005905802450908018), (('SDG', '&'), 0.0005905802450908018), (('curtis_l_kebler', '@'), 0.0005905802450908018), (('dparque', '@'), 0.0005905802450908018), (('@', 'ect.enron.com'), 0.0005905802450908018), (('iepa.com', '>'), 0.0005905802450908018), (('TIME', 'DATE'), 0.0005905802450908018), (('``', 'Bob'), 0.0005905802450908018), (('attached', 'file'), 0.0005905802450908018), (('file', ':'), 0.0005905802450908018), (('market', '.'), 0.0005905802450908018), (('Bay', 'Area'), 0.0005905802450908018), (('advice', 'letter'), 0.0005905802450908018), (('.', 'Thanks'), 0.0005905802450908018), (('Coordinators', 'Participating'), 0.0005905802450908018), (('Participating', 'Transmission'), 0.0005905802450908018), (('Transmission', 'Owners'), 0.0005905802450908018), (('request', 'information'), 0.0005905802450908018), (('Electricity', 'Oversight'), 0.0005905802450908018), (('Oversight', 'Board'), 0.0005905802450908018)]\n",
            "brawner-s [((':', '>'), 0.0005037392955399698), (('Erck', \"''\"), 0.0005037392955399698), ((')', 'n.'), 0.0005037392955399698), (('>', 'And'), 0.0004649901189599721), (('@', 'worldnet.att.net'), 0.0004649901189599721), ((\"''\", 'Pamela'), 0.0004649901189599721), (('Pamela', 'Anderson'), 0.0004649901189599721), (('<', 'pama9'), 0.0004649901189599721), (('pama9', '@'), 0.0004649901189599721), (('@', 'flash.net'), 0.0004649901189599721), (('flash.net', '>'), 0.0004649901189599721), ((',', '<'), 0.0004649901189599721), (('enron.com', '>'), 0.0004649901189599721), ((':', 'rstevens'), 0.0004649901189599721), ((':', 'Time'), 0.0004649901189599721), (('Time', '&'), 0.0004649901189599721), (('&', 'Friends'), 0.0004649901189599721), (('Friends', '>'), 0.0004649901189599721), (('<', 'rstevens'), 0.0004649901189599721), ((',', '6'), 0.0004649901189599721)]\n",
            "carson-m [(('Hotmail', 'http'), 0.0006434178355424012), ((':', '//www.hotmail.com'), 0.0006434178355424012), (('DEF', '--'), 0.0006434178355424012), (('dttowns', '@'), 0.0006434178355424012), (('@', 'swbell.net'), 0.0006434178355424012), (('yahoo.com', ','), 0.0006434178355424012), (('.', 'If'), 0.0006434178355424012), (('Beastie', 'Boys'), 0.0006434178355424012), ((':', 'http'), 0.0006434178355424012), ((':', '//p04.com/t.d'), 0.0006434178355424012), (('//p04.com/t.d', '?'), 0.0006434178355424012), (('TIME', '>'), 0.0006434178355424012), (('>', 'I'), 0.0006434178355424012), (('!', '>'), 0.0006434178355424012), (('jklinger73', '@'), 0.0006434178355424012), (('>', 'http'), 0.0006434178355424012), (('ca', \"n't\"), 0.000514734268433921), (('my', 'wife'), 0.000514734268433921), (('would', 'like'), 0.000514734268433921), (('attend', '.'), 0.000514734268433921)]\n",
            "farmer-d [(('.', 'So'), 0.0004884740900870938), (('please', 'let'), 0.0004884740900870938), (('Farmer', 'DATE'), 0.00047808102434056), (('Also', ','), 0.00046768795859402604), (('PEC', ','), 0.00045729489284749214), (('-', 'Enron'), 0.00045729489284749214), (('AM', '--'), 0.00045729489284749214), ((',', 'Mary'), 0.00045729489284749214), (('2000', '.'), 0.00044690182710095823), (('>', 'DATE'), 0.00044690182710095823), ((')', ','), 0.00044690182710095823), ((',', 'Pat'), 0.00044690182710095823), (('Sitara', '#'), 0.00043650876135442433), (('.', 'Do'), 0.00042611569560789043), (('new', 'deal'), 0.00042611569560789043), (('this', 'meter'), 0.00042611569560789043), (('The', 'deal'), 0.00042611569560789043), (('.', '>'), 0.00042611569560789043), (('have', 'questions'), 0.00041572262986135653), (('Clynes/Corp/Enron', '@'), 0.00041572262986135653)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREDICT AUTHOR FROM TEST DATA**"
      ],
      "metadata": {
        "id": "HTucKfsn1Dp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEMO, ONE AUTHOR, REUSED TEST/TRAINING DATA"
      ],
      "metadata": {
        "id": "HohPjhgq1oyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicted_author_from_tokens(test_email_tokens):\n",
        "  test_email_bigrams = list(bigrams(test_email_tokens))\n",
        "\n",
        "  author_test_expected_prob_log = {}\n",
        "  for author in project_authors:\n",
        "    bigram_freqs = author_bigram_frequencies[author]\n",
        "    unseen_bigram_probability = 0.000001 # TODO: calculate this in a more principled way\n",
        "    # do all probability calculations in log space, avoid min. float value/precision\n",
        "    email_probability_log = math.log(1.0)\n",
        "    # print(author, \"\\tunseen bigram freq:\", unseen_bigram_probability, \"\\tleast common bigram freq:\", bigram_freqs.most_common()[-1][1])\n",
        "    for bigram in test_email_bigrams:\n",
        "      bigram_probability = bigram_freqs.get(bigram) if bigram in bigram_freqs else unseen_bigram_probability\n",
        "      # print(email_probability_log, '+', bigram_probability)\n",
        "      email_probability_log += math.log(bigram_probability)\n",
        "    author_test_expected_prob_log[author] = email_probability_log\n",
        "\n",
        "  most_likely_author_and_prob = [None, -math.inf] # {author: probability}\n",
        "  for author in project_authors:\n",
        "    predicted_prob = author_test_expected_prob_log[author]\n",
        "    if predicted_prob > most_likely_author_and_prob[1]:\n",
        "      most_likely_author_and_prob[0] = author\n",
        "      most_likely_author_and_prob[1] = predicted_prob\n",
        "\n",
        "  # DEBUG OUTPUT (function internal)\n",
        "  # print(test_email_tokens)\n",
        "  # for author in project_authors:\n",
        "    # print(author, author_test_expected_prob_log[author])\n",
        "\n",
        "  return most_likely_author_and_prob\n",
        "\n",
        "def get_predicted_author(test_email):\n",
        "  test_email_tokenized = nltk.word_tokenize(test_email)\n",
        "  prediction = get_predicted_author_from_tokens(test_email_tokenized)\n",
        "  return prediction\n",
        "\n",
        "test_email_tokens = authors_testing_tokenized_emails['allen-p'][1]\n",
        "print(\"predicted author (from tokens w/ cleanup):\\t\", get_predicted_author_from_tokens(test_email_tokens))\n",
        "# test_email = authors_emails['allen-p'][1]\n",
        "# print(\"predicted author (raw email):\\t\\t\\t\", get_predicted_author(test_email))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29hr4T8l1JFf",
        "outputId": "32eea873-ea20-47aa-868c-ec0220410620"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted author (from tokens w/ cleanup):\t ['allen-p', -1134.1135390384936]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for all emails (TODO: only check test emails)\n",
        "authors_predictions = {}\n",
        "for author in project_authors:\n",
        "  email_predictions = []\n",
        "  for email in authors_testing_tokenized_emails[author]:\n",
        "    predicted_author = get_predicted_author_from_tokens(email)[0]\n",
        "    email_predictions.append(predicted_author)\n",
        "  authors_predictions[author] = email_predictions\n",
        "\n",
        "print(\"SAMPLE\")\n",
        "print(\"emails...\")\n",
        "for author in project_authors:\n",
        "  print(\"written by:\", author)\n",
        "  for prediction in authors_predictions[author][0:5]:\n",
        "    print(\"\\tpredicted author:\", prediction)\n",
        "print(\"(each line is a new email)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utlcBzpv1vGz",
        "outputId": "3766eb13-bf38-4e1f-b436-707c5686ddbd"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE\n",
            "emails...\n",
            "written by: allen-p\n",
            "\tpredicted author: allen-p\n",
            "\tpredicted author: allen-p\n",
            "\tpredicted author: beck-s\n",
            "\tpredicted author: farmer-d\n",
            "\tpredicted author: allen-p\n",
            "written by: bass-e\n",
            "\tpredicted author: bass-e\n",
            "\tpredicted author: arnold-j\n",
            "\tpredicted author: beck-s\n",
            "\tpredicted author: bass-e\n",
            "\tpredicted author: farmer-d\n",
            "written by: buy-r\n",
            "\tpredicted author: delainey-d\n",
            "\tpredicted author: farmer-d\n",
            "\tpredicted author: buy-r\n",
            "\tpredicted author: allen-p\n",
            "\tpredicted author: buy-r\n",
            "written by: delainey-d\n",
            "\tpredicted author: delainey-d\n",
            "\tpredicted author: delainey-d\n",
            "\tpredicted author: fossum-d\n",
            "\tpredicted author: delainey-d\n",
            "\tpredicted author: delainey-d\n",
            "written by: fossum-d\n",
            "\tpredicted author: fossum-d\n",
            "\tpredicted author: fossum-d\n",
            "\tpredicted author: fossum-d\n",
            "\tpredicted author: beck-s\n",
            "\tpredicted author: fossum-d\n",
            "written by: arnold-j\n",
            "\tpredicted author: arnold-j\n",
            "\tpredicted author: beck-s\n",
            "\tpredicted author: farmer-d\n",
            "\tpredicted author: bass-e\n",
            "\tpredicted author: arnold-j\n",
            "written by: beck-s\n",
            "\tpredicted author: beck-s\n",
            "\tpredicted author: beck-s\n",
            "\tpredicted author: beck-s\n",
            "\tpredicted author: beck-s\n",
            "\tpredicted author: beck-s\n",
            "written by: campbell-l\n",
            "\tpredicted author: brawner-s\n",
            "\tpredicted author: campbell-l\n",
            "\tpredicted author: campbell-l\n",
            "\tpredicted author: campbell-l\n",
            "\tpredicted author: badeer-r\n",
            "written by: badeer-r\n",
            "\tpredicted author: bass-e\n",
            "\tpredicted author: beck-s\n",
            "\tpredicted author: badeer-r\n",
            "\tpredicted author: allen-p\n",
            "\tpredicted author: beck-s\n",
            "written by: brawner-s\n",
            "\tpredicted author: brawner-s\n",
            "\tpredicted author: brawner-s\n",
            "\tpredicted author: bass-e\n",
            "\tpredicted author: fossum-d\n",
            "\tpredicted author: brawner-s\n",
            "written by: carson-m\n",
            "\tpredicted author: bass-e\n",
            "\tpredicted author: carson-m\n",
            "\tpredicted author: carson-m\n",
            "\tpredicted author: carson-m\n",
            "\tpredicted author: carson-m\n",
            "written by: farmer-d\n",
            "\tpredicted author: farmer-d\n",
            "\tpredicted author: farmer-d\n",
            "\tpredicted author: farmer-d\n",
            "\tpredicted author: farmer-d\n",
            "\tpredicted author: farmer-d\n",
            "(each line is a new email)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST PRECISION & RECALL**"
      ],
      "metadata": {
        "id": "ZtFyP8FVVQ_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# determine precision, recall for each author\n",
        "num_emails_by_author = {}\n",
        "num_true_positives_by_author = {}\n",
        "num_total_positives_by_author = {}\n",
        "\n",
        "# calc. num_emails_by_author, num_emails_total\n",
        "for author in project_authors:\n",
        "  num_emails_by_author[author] = len(authors_testing_tokenized_emails[author])\n",
        "num_emails_total = sum(num_emails_by_author.values())\n",
        "\n",
        "# initialize positive counts\n",
        "for author in project_authors:\n",
        "  num_true_positives_by_author[author] = 0\n",
        "  num_total_positives_by_author[author] = 0\n",
        "# calc. num positives\n",
        "for author in project_authors:\n",
        "  for predicted_auth in authors_predictions[author]:\n",
        "    if author == predicted_auth:\n",
        "      num_true_positives_by_author[predicted_auth]+= 1\n",
        "    num_total_positives_by_author[predicted_auth] += 1\n",
        "\n",
        "# derive precision, by author (true_pos / tot_pos)\n",
        "authors_precision = {}\n",
        "for author in project_authors:\n",
        "  num_true_pos = num_true_positives_by_author[author]\n",
        "  num_tot_pos = num_total_positives_by_author[author]\n",
        "  precision = num_true_pos / num_tot_pos if num_tot_pos != 0 else 0\n",
        "  authors_precision[author] = precision\n",
        "\n",
        "# derive recall, by author (true_pos / num_by_auth)\n",
        "authors_recall = {}\n",
        "for author in project_authors:\n",
        "  num_true_pos = num_true_positives_by_author[author]\n",
        "  num_by_auth = num_emails_by_author[author]\n",
        "  recall = num_true_pos / num_by_auth if num_by_auth != 0 else 0\n",
        "  authors_recall[author] = recall\n",
        "\n",
        "\n",
        "print(\"num test emails    \\t\", num_emails_total)\n",
        "print(\"num_by_author      \\t\", num_emails_by_author)\n",
        "print('num_true_positives \\t', num_true_positives_by_author)\n",
        "print('num_total_positives\\t', num_total_positives_by_author)\n",
        "print()\n",
        "print('precision')\n",
        "for entry in authors_precision.items():\n",
        "  print(\"\\t\", entry)\n",
        "print('recall')\n",
        "for entry in authors_recall.items():\n",
        "  print(\"\\t\", entry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-QZw_1uS0bJ",
        "outputId": "5808dd15-7256-4321-ab52-2c47bb10c65a"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num test emails    \t 743\n",
            "num_by_author      \t {'allen-p': 61, 'bass-e': 141, 'buy-r': 17, 'delainey-d': 88, 'fossum-d': 110, 'arnold-j': 82, 'beck-s': 110, 'campbell-l': 20, 'badeer-r': 6, 'brawner-s': 15, 'carson-m': 18, 'farmer-d': 75}\n",
            "num_true_positives \t {'allen-p': 40, 'bass-e': 114, 'buy-r': 5, 'delainey-d': 74, 'fossum-d': 105, 'arnold-j': 36, 'beck-s': 100, 'campbell-l': 11, 'badeer-r': 2, 'brawner-s': 7, 'carson-m': 8, 'farmer-d': 65}\n",
            "num_total_positives\t {'allen-p': 62, 'bass-e': 137, 'buy-r': 8, 'delainey-d': 93, 'fossum-d': 120, 'arnold-j': 40, 'beck-s': 135, 'campbell-l': 13, 'badeer-r': 4, 'brawner-s': 10, 'carson-m': 26, 'farmer-d': 95}\n",
            "\n",
            "precision\n",
            "\t ('allen-p', 0.6451612903225806)\n",
            "\t ('bass-e', 0.8321167883211679)\n",
            "\t ('buy-r', 0.625)\n",
            "\t ('delainey-d', 0.7956989247311828)\n",
            "\t ('fossum-d', 0.875)\n",
            "\t ('arnold-j', 0.9)\n",
            "\t ('beck-s', 0.7407407407407407)\n",
            "\t ('campbell-l', 0.8461538461538461)\n",
            "\t ('badeer-r', 0.5)\n",
            "\t ('brawner-s', 0.7)\n",
            "\t ('carson-m', 0.3076923076923077)\n",
            "\t ('farmer-d', 0.6842105263157895)\n",
            "recall\n",
            "\t ('allen-p', 0.6557377049180327)\n",
            "\t ('bass-e', 0.8085106382978723)\n",
            "\t ('buy-r', 0.29411764705882354)\n",
            "\t ('delainey-d', 0.8409090909090909)\n",
            "\t ('fossum-d', 0.9545454545454546)\n",
            "\t ('arnold-j', 0.43902439024390244)\n",
            "\t ('beck-s', 0.9090909090909091)\n",
            "\t ('campbell-l', 0.55)\n",
            "\t ('badeer-r', 0.3333333333333333)\n",
            "\t ('brawner-s', 0.4666666666666667)\n",
            "\t ('carson-m', 0.4444444444444444)\n",
            "\t ('farmer-d', 0.8666666666666667)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine precision, recall across all authors\n",
        "\n",
        "all_true_pos = sum(num_true_positives_by_author.values()) \n",
        "all_pos = sum(num_total_positives_by_author.values())\n",
        "num_emails_total # defined in previous block\n",
        "\n",
        "# overall precision\n",
        "precision = all_true_pos / all_pos\n",
        "print(f\"all-author precision:\\t {precision} = {all_true_pos} / {all_pos}\")\n",
        "\n",
        "#overall recall\n",
        "recall = all_true_pos / num_emails_total\n",
        "print(f\"all-author recall:   \\t {recall} = {all_true_pos} / {num_emails_total}\")\n",
        "\n",
        "print(\"(These numbers are the same because, across all authors, every email is a 'positive' result for someone; i.e. 'all_pos' == 'num_emails_total')\")\n",
        "print(\"(This program always guesses that the author is a known author.)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un5xlXxXV0Rc",
        "outputId": "a96ac531-7478-4c21-e4bc-9d1c99db4fde"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all-author precision:\t 0.7631224764468372 = 567 / 743\n",
            "all-author recall:   \t 0.7631224764468372 = 567 / 743\n",
            "(These numbers are the same because, across all authors, every email is a 'positive' result for someone; i.e. 'all_pos' == 'num_emails_total')\n",
            "(This program always guesses that the author is a known author.)\n"
          ]
        }
      ]
    }
  ]
}